>论文标题：基于单目视觉的同时定位与地图构建方法综述  
发表时间：2016  
研究组织：浙江大学  
本文标签：SLAM、CCF-A  


# 速读概览：
## 1.主要内容？ 
单目SLAM综述。


## 0.摘要
本文首先介绍了基于视觉的SLAM的基本原理，然后介绍了几个代表性的基于单目SLAM的方法并做深入分析和比较。


## 0.5.导入部分
* GPS无法在室内及遮挡严重的室外环境中使用，且定位精度较低；高精度的惯导系统成本太高且难以民用；基于无线信号的定位方法需要事先布置使用场景等。而基于视觉的SLAM硬件成本低廉、小场景范围内精度较高、无需预先布置场景等，逐渐成为常采用的定位方案。
* SLAM最早源于机器人领域，目标是在一个未知的环境中实时重建环境的三维结构并同时对机器人进行定位。在计算机视觉领域，与之类似的技术是运动推断结构（SFM）。


## 1.V-SLAM的基本原理
* V-SLAM技术可以根据拍摄的视频信息推断出摄像头在未知环境中的方位, 并同时构建环境 地图, 其基本原理为多视图几何原理。
* V-SLAM的目标为同时恢复出每帧图像对应的相机运动参数$C_1...C_m$, 及场景三维结构$X_1...X_n$。每个相机运动参数$C_i$包含了相机的位置和朝向信息, 通常表达为一个3×3的旋转矩阵$R_i$和一个三维位置变量$P_i$。$R_i$,$P_i$将一个世界坐
标系下的三维点$X_j$变换至$C_i$的局部坐标系
$$(X_{ij},Y_{ij},Z_{ij})^T = R_i(X_j)-p_i \tag{1}$$
进而投影到图像中
$$h_{ij} = (f_xX_{ij}/Z_{ij}+c_x,f_yY_{ij}/Z_{ij}+c_y)^T \tag{2}$$
其中，$f_x$和$f_y$分别为沿图像x，y轴的图像焦距，$(c_x,c_y)$为镜头光心在图像中的位置，通常假设这些参数已事先标定且保持不变。由(1)(2)可知，三维点在图像中的投影位置$h_{ij}$可表示为一个关于$C_i$和$X_j$的函数，记为
$$h_{ij} = h(C_i,X_j) \tag{3}$$
* V-SLAM算法需要将不同图像中对应于相同场景点的图像点匹配起来，通过求解优化如下目标函数
$$\mathop {argmin}_{C_1...C_m,X_1...X_n} \sum_{i=1}^m\sum_{j=1}^n \left \| h(C_i,X_j)-\hat x_{ij} \right \|_{\sum_{ij}} \tag{4}$$
得到一组最优的$C_1...C_m$,$X_1...X_n$，使得所有$X_j$在$C_i$图像中的投影位置$h_{ij}$与观测到的图像点位置$x_{ij}$尽可能靠近。假设图像观测点符合高斯分布$x_{ij}\sim N(\hat x_{ij},\sum_{ij})$,$\left \| e \right \|_{\sum} = e^T\sum ^{-1}e$。求解目标函数(4)的过程也称为集束调整（BA），可利用线性方程的稀疏结构高效求解。
* 由于V-SLAM需要进行图像特征的匹配，因此其稳定性严重依赖于特征的丰富程度。可以通过在V-SLAM中加入其他传感器信息解决这一问题。目前最常用的是在V-SLAM中结合IMU数据（加速度、角速度）。这样的SLAM称为VIN或VI-SLAM。将相邻2帧间的所有IMU数据标记为集合$Z_i = {z_1...z_{n_i}}$，VI-SLAM方法一般求解优化如下目标函数
$$\mathop {argmin}_{C_1...C_m,X_1...X_n} \sum_{i=1}^m\sum_{j=1}^n \left \| h(C_i,X_j)-\hat x_{ij} \right \|_{\sum_{ij}}+\sum _{i=1}^{m-1}\left \| f(C_i,Z_i)-C_{i+1} \right \|_{\Gamma _i} \tag{5}$$
与(4)相比，VI-SLAM引入了一个运动方程，其中$f(C_i,Z_i)$为$Z_i$作用于$C_i$后的运动参数，$\Gamma _i$为运动方程的协方差矩阵。通常V-SLAM需求解每一时刻的运动速度$v_i$和IMU数据的偏移量$b_i$，即$C_i = (R_i,p_i,v_i,b_i)$。
* 类似的原理可应用于其他传感器数据，如引入GPS数据$p_i^G$，只需在能量函数中再引入一项
$$\mathop {argmin}_{C_1...C_m,X_1...X_n} \sum_{i=1}^m\sum_{j=1}^n \left \| h(C_i,X_j)-\hat x_{ij} \right \|_{\sum_{ij}}+\sum _{i=1}^{m-1}\left \| f(C_i,Z_i)-C_{i+1} \right \|_{\Gamma _i}+ \sum_{i=1}^{m-1}\left \| p_i-\hat p_i^G\right \|_{\Lambda_i} \tag{6}$$
此处，假设GPS观测值符合高斯分布
$p_i^G \sim N(\hat p_i^G,\Lambda_i)$

## 2.代表性单目V-SLAM系统
* 主流的V-SLAM方法大致可以分为3类：基于滤波器、基于关键帧BA和基于直接跟踪的V-SLAM。
### A.基于滤波器的V-SLAM
* 思想：将每一时刻t的系统状态用一个高斯概率模型表达，$x_t\sim N(\hat x_t ,P_t)$，$\hat x_t$为当前时刻系统状态估计值，$P_t$为该估计值误差的协方差矩阵。系统状态由一滤波器不断更新。不同的状态设计和滤波方式衍生出不同的SLAM系统。
* MonoSLAM是第一个成功基于单目摄像头的纯视觉SLAM系统。MonoSLAM的状态$x_t$由t时刻的相机运动参数$C_t$和所有三维点位置$X_1...X_n$构成，每一时刻的相机方位均带有一个概率偏差。同样，每个三维点位置也带有一个概率偏差，可以用一个三维椭球表示，椭球中心为估计值，椭球体积表示不确定成都；不同场景点之间，以及场景点和$C_t$之间均有概率关联。在此概率模型下，场景点投影至图像的形状为一个投影概率椭圆。MonoSLAM 为每帧图像中抽取 Shi-Tomasi 角点, 在投影椭圆中主动搜索(active search)特征点匹配。
  * MonoSLAM的滤波器选用的是扩展卡尔曼滤波器。在预测阶段，采用运动方程
$$C_t = f(C_{t-1},a_v\Delta t,a_\omega \Delta t) \tag{7}$$
其中，$a_v$和$a_\omega$分别为线性和旋转加速度，算法假设$a_v \sim N(0,\Gamma _v)$，$a_\omega \sim N(0,\Gamma_\omega)$，$\Delta t$为相邻2帧时间差。在更新阶段，采用投影方程
$$\hat x_j = h(C_t,X_j)+n_j \tag{8}$$
其中，$\hat x_j$为当前帧观测到$X_j$的图像点位置，$n_j \sim N(0,\sum_j)$。与(5)相比，MonoSLAM每一时刻只需估计当前时刻状态$x_t$，之前所有时刻的相机运动参数${C_1...C_{t-1}}$全部不参与计算，由此减少计算量。

* 传统 EKF 方法最主要的局限性如下:
  * 如果预测函数和更新函数为非线性(通常 V-SLAM 问题都是非线性的), 那么 EKF 并不能保证全局最优, 与 Levenberg-Marquardt等迭代的非线性优化技术相比, 更容易造成误差累积. 如果上一帧处理完成时刻的估计值尚未精确, 传递至下一帧的先验信息便带有误差; 由于上一帧状态不再变化, 所以先验信息中的误差便无法消除, 误差不断向后传递造成误差累积.
  * 若将三维点引入状态变量, 则每一时刻的计算复杂度为O(n3), 因此只能处理几百个点的小场景.
* 为了缓解 EKF 方法的计算复杂度问题, 2007年提出了 MSCKF. MSCKF 是一个 VI-SLAM 方法, 在预测阶段, 使用 IMU 数据进行传递系统状态; 在更新阶段,MSCKF将邻近的 l 帧相机运动参数全部包含进一个状态变量集合$C={C_{t-l+1}...C_t}$. C中每个$C_i$的估计值均在不断优化, 通常移出 C 前$C_i$已较为精确, 由此缓解误差累积. 除此之外, MSCKF 对所有三维点进行消元, 将$C_i$与$X_j$间的二元约束转换为$C={C_{t-l+1}...C_t}$间的多元约束, 从而将O(n3) 的计算复杂度简化为 O(nl3) . 因为一般来说$l<<n$, 而且为常数, 所以该方法可以大大降低计算复杂度, 将原来的跟三维点数成立方关系降到了线性关系.

### B.基于关键帧BA的V-SLAM
* PTAM是实时SFM系统，也是首个基于关键帧BA的单目V-SLAM系统。其思想为：将相机跟踪和地图构建作为 2 个独立的任务在 2 个线程并行执行. 地图构建线程仅维护原视频流中稀疏抽取的关键帧及关键帧中可见的三维点, 这样就可以非常高效地求解目标函数(4)(即 BA); 有了 BA 恢复的精确三维结构, 相机跟踪线程作为前台线程, 仅需优化当前帧运动参数$C_t$,足以达到实时的计算效率.
  * 前台线程通过一个匀速运动模型预测当前帧方位, 以搜索地图中的三维点在当前 帧图像中对应的FAST角点, 并根据匹配关系优化当前帧方位。
  $$argmin_{C_t}\sum _{j=1}^nw_j \left \| h(C_t,X_j)-\hat x_j \right \|_{\sum_j} \tag{9}$$
  其中$w_j$是 Tukey 函数对应的权重, 用于缓解误匹配对结果的影响. 如果成功匹配点数不足(如因图像模糊、快速运动等), 则判断跟踪失败, 开始重定位——将当前帧与已有关键帧的缩略图进行比较, 选择最相似的关键帧作为当前帧方位的预测, 重复上述特征匹配和方位优化步骤. 如果跟踪成功, 判断$C_t$是否满足关键帧条件, 一旦符合, 系统将当前帧作为新的关键帧传递给后台构建地图. 后台线程沿极线匹配不同关键帧之间对应于相同场景点的图像特 征点, 通过三角化恢复这些场景点三维位置, 并对所有关键帧和三维点运行 BA, 恢复精确的三维地图。

* ORB-SLAM 是目前性能最好的单目 V-SLAM 系统之一。ORB-SLAM 基本延续了 PTAM 的算法框架, 但对框架中的大部分组件都做了改进, 归纳起来主要有 4 点:   
  * ORB-SLAM 选用了 ORB 特征, 基于 ORB 描述量的特征匹配和重定位, 都比 PTAM 具有更好的视角不变性. 此外, 新增三维点的特征匹配效率更高, 因此能更及时地扩展场景. 扩展场景及时与否决定了后续帧是否能稳定跟踪；
  * ORB-SLAM加入了循环回路的检测和闭合机制, 以消除误差累积. 系统采用与重定位相同的方法来检测回路(匹配回路两侧关键帧上的公共点), 通过方位图优化来闭合回路. 关键帧作为方位图的节点, 每个关键帧被赋予一个相似变换$\xi _i$以矫正其方位; 方位图的边表示关键帧之间存在特征匹配，2团匹配的三维点云通过坐标对齐可求解一个相似变换$\xi _{ij}$；系统选用g2o优化方位图，以闭合回路。
$$argmin_{\xi_1,...,\xi_m}\sum_{(\xi_{ij},\sum _ {ij})}(\xi_{ij}\circ\xi_i^{-1}\circ\xi_j)^T \sum _{ij}^{-1}(\xi_{ij}\circ\xi_i^{-1}\circ\xi_j) \tag{10}$$
    其中，$\sum_{ij}$为$\xi_{ij}$的协方差矩阵，操作符$\circ$按顺序连接 2 个相似变换. 与全局 BA 相比, 方位图优化极大简化了全局优化的计算量, 因此 ORB-SLAM 能处理大尺度场景。BA 在系统中只运行于局部场景;
  * PTAM 需要用户指定 2 帧来初始化系统, 2 帧间既要有足够的公共点, 又要有足够的平移量. 平移运动为这些公共点提供视差, 只有足够的视差才能三角化出精确的三维位置. ORB-SLAM 通过检测视差来自动选择初始化的 2 帧;
  * PTAM 扩展场景时也要求新加入的关键帧提供足够的视差, 导致场景往往难以扩展. ORB-SLAM 采用一种更鲁棒的关键帧和三维点的选择机制——先用宽松的判断条件尽可能及时地加入新的关键帧和三维点, 以保证后续帧的鲁棒跟踪; 再用严格的判断条件删除冗余的关键帧和不稳定的三维点, 以保证 BA 的效率和精度。

### C.基于直接跟踪的V-SLAM
