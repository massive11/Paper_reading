>论文标题：Road-map: A Light-Weight Semantic Map for Visual Localization towards Autonomous Driving  
发表时间：2021  
研究组织：华为车BU  
本文标签：自动驾驶、语义地图、ICRA


# 四问：
## 1.针对什么问题？ 
 
## 2.采用什么方法？  

## 3.达到什么效果？  

## 4.存在什么不足？



# 论文精读
## 0.摘要
### 讨论的问题：
    本文提出了一种轻量级的定位方式，依赖低成本的摄像头和紧凑的视觉语义地图。地图通过配有丰富的传感器的车辆以众包方式制作和更新。

## 1.介绍
* 定位对于自动驾驶来说是最基础的部分，而高精度的定位依赖高精度的传感器和高精度的地图。当下在厘米级定位方面，常用的两种传感器是RTK-GPS和雷达。  
RTK-GPS通过接受来自卫星和地面站的信号，在开阔区域提供准确的全球姿态。  
雷达捕获周围环境的点云。  
但这两种方式的成本较高、点云地图会占用大量内存、高精地图的生产消耗大量的人力难以保证实时更新。这些缺点使得这两种方式对量产自动驾驶车辆来说不够理想。
* 本文的地图包括车道线、斑马线、停止线等几种语义元素，通过基于学习的语义分割来提取有用的地标。然后将语义地标从2D恢复到3D，并注册到本地地图中，本地地图上传到云服务器上。云服务器合并不同的车辆捕获到的数据，压缩为全局语义地图。
* 本文提出的轻量级定位方案包括车载地图、云端地图维护和用户端定位三个部分。**核心思路**是使用装配丰富的传感器的车辆每天自动收集数据并更新地图来帮助低成本的量产车辆。

## 2.文献综述
传统的基于视觉的方法集中在SLAM在小规模的室内环境的应用上。但是对于自动驾驶任务，需要更多地集中在大规模的室外环境方面。
### 关于传统视觉SLAM
* 视觉里程计是视觉SLAM领域的一个经典话题，比较流行的方法包括仅相机方法和视觉惯性组合方法。
* 一些方法通过增加先验地图的方式扩展视觉里程计，将该问题转化为固定坐标系下的定位问题。
* 一些方法事先构建视觉地图，然后在该地图内重新定位相机姿势。  
  具体来说，基于视觉的方法通过描述符匹配来针对视觉特征图定位相机姿势。这种地图包含了上千个3D视觉特征及其描述符。还有一些方法利用ORB功能构建环境地图，然后可以使用该地图通过ORB描述符匹配来重新定位相机。
* 此外，一些方法可以自动将多个序列合并到一个全局框架中。
* 对于自动驾驶任务，burki等人证明车辆能够通过道路上的稀疏特征图进行定位  
**从本质来说，传统的基于外观的方法在长期应用中容易受到光线、视角和时间变化的影响。**

### 基于道路的定位
* 基于道路的方法充分利用了自动驾驶场景中的道路特征。道路要素包含地面上的各种标记，如车道线、路缘石和地面标识等，以及一些3D元素，如交通灯和交通标志。与传统特征相比，这些道路上的标记丰富且稳定，对时间和光照的变化也有很强的抵抗力。  
    通常来说，精确的先验地图是必要的，一般通过高精度的传感器来构建。车辆通过与这张地图进行视觉检测匹配来定位。
* 具体来说，一些方法通过检测路缘和车道线以及在高精度地图上匹配这些元素的结构来定位相机。一些方法通过道路标记以及检测其角点用于定位。也有人通过非线性优化来匹配道路标记与地图。车辆里程计和对极几何也被用来估计6-DoF相机姿态。
* 还有一些研究者集中于构造道路地图。文献「19」检测图像上的车道并使用里程计生成局部网格图，通过局部地图拼接进一步优化了姿势。文献「20」对道路标记进行分类，信息化类别能够用来避免歧义。闭环和姿态图优化也能用于消除漂移并保持全局一致性。文献「21」通过大量路标构建地下停车场的语义地图
**但是，由于会话间的特征匹配消耗了大量计算，应用起来非常困难。**

### 系统总览
* 系统分为三个部分，车端测图、云端建图和用户端定位。
* 车端测图：语义特征是分割网络从前视图像中提取到的，然后基于优化过的车辆姿态将语义特征投影到真实世界框架中。局部语义地图在车端建立，并上川岛云端地图服务器中。
* 云端建图：云服务器收集海量车辆传来的局部地图，并合并为全局地图，再通过轮廓提取压缩地图。最后，将压缩后的语义地图发送给终端用户。