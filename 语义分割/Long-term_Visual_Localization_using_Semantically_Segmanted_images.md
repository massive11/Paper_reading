>论文标题：Long-term Visual Localization using Semantically Segmented Images  
发表时间：2018  
研究组织：查尔姆斯理工大学  
本文标签：自动驾驶、语义分割、视觉定位、ICRA

# **待完善**

# 速读概览：
## 1.针对什么问题？ 
    视觉导航中的长期定位问题（不同的季节中同一物体的视觉外观会有较大的变化）。
## 2.采用什么方法？  
    本文采用基于语义分割图像和语义点特征图的定位算法，替代传统的描述特征的描述符，每个点只有其三维坐标及其所在对象的语义类别来描述。
## 3.达到什么效果？  

## 4.存在什么不足？



# 论文精读
## 0.摘要
强大的跨季节定位是自动驾驶车辆长期视觉导航的主要挑战之一。在本文中，我们利用图像语义分割的最新进展，即每个像素被分配到一个与其代表的对象类型相关的标签，来解决长期视觉定位的问题。我们展示了环境的语义标记的3D点图以及语义分割图像，能够高效的用于车辆定位，无需详细的特征描述符（SIFT、SURF等）。因此，我们不依赖于手工制作的特征描述符，而是依赖于图像分割器的训练。与传统的基于描述符的地图相比，我们的结果图占用更小的存储空间。将基于粒子过滤器的语义定位解决方案与基于SIFT特征的解决方案进行对比，即使一年中有较大的季节变化，我们的方法也与有更大规模更具描述性的SIFT特征相当，并且在大部分时候能够以低于1m的误差进行定位。
### 讨论的问题：
    使用语义分割解决视觉导航长期定位的问题。

### 主要贡献：
    1.依赖图像分割器进行训练，无需手动设计特征描述符，结果图占用更小的存储空间；
    2.面对跨度一年的较大的季节变化，表现与更大规模更具描述性的传统方法持平，大部分时候误差小于1m。

## 1.介绍
* 自动驾驶车辆虽然能在未知的环境中导航，但是通常依赖预先制作好的地图提供有关前方道路的信息。
* 自动驾驶车辆的核心任务就是通过车载的摄像头、雷达、激光雷达等传感器观察到的情况得到他们在地图中的当前位置。为此，除了导航信息，地图通常还需要描绘能够较容易的被车辆配备的传感器检测到的地标的位置。
* 传统方法将图像中特征点的位置作为路标，定位通过当前图像中特征点与地图中的特征对应匹配来实现。许多方法已经研究了如何建立这种2D-3D的对应关系，建立之后，他们能够用于计算完整的六自由度相机姿态。但是特征点的外表易受光照、天气以及季节变化的影响。
* 传统描述子的方法在精心设计之下对于均匀的光照变化与较小的尺度变化具有较好的鲁棒性，但是大多数并非设计为针对巨大光照变化和季节差异所设计的，最常用的特征检测器在面对应对这些变化时也非常敏感。在点的匹配都不能保证的情况下，自然无法取得较好的定位效果。
* 上述问题能够归结为寻找一种适合定位且随时间不变又紧凑的环境描述。如果这种方法不能实现，就只能通过不断的更新地图来解决情况变化的问题。  
    **本文使用语义图像分割的最新进展，基于这些语义分割图像和语义点特征图来设计定位算法，以此取代使用传统的描述符来描述特征。每个点仅由它的3D位置和它所在对象的语义类别来描述。**

## 2.问题陈述
    本文主要涉及使用车载摄像头在点特征图中连续定位查找车辆当前位置的问题。
### A.观测
* 观测结果是在已知但不规律的时间间隔下得到的。每次测量的时间距离为t。
  （1）里程计：从车辆状态数据中，可以提取3D速度和3D旋转速度，分别表示为
    $$V_t = [v_t^x,v_t^y,v_t^z]^T$$
    $$\omega_t = [\omega_t^x,\omega_t^y,\omega_t^z]^T$$
   速度是相对于车辆框架给出的，上标表示组件沿着或者围绕哪个轴运动。假设所有测量都受加性高斯噪声的影响，旋转速度的测量也受到缓慢变化的偏差的影响。  

   （2）图像：车辆配备了一对校准的摄像头。每个相机以15Hz的频率拍摄RGB图像。尽管可以直接使用这些原始图片，但通常将图像压缩为具有关联描述符向量的特征点集来降低复杂度。由此，图像被预处理后产生一组$n_t$特征点和描述符对。
   $$f_t = {<u_t^i,d_t^i>}_{i=1}^{n_t}$$
   其中，$u_t^i$是归一化的图像坐标，$d_t^i$是相关的描述符向量。
   在我们提出的方法（语义点特征图）中，$f_t$是密集的，并包含图像的每个像素的元素。

### B.地图
假设我们有一个由M个点特征组成的预先构建的点特征图。此时地图可以表示为：
$$M = {<U_i,D_i,V_i>}_{i=1}^{M}$$
每一个点特征由其全局坐标表示
$$U_i = [U_i^e,U_i^n,U_i^u]$$
$D_i$是其所关联的描述符向量
$V_i$是能见度
$$V_i = [\rho_i,\gamma_a,\gamma_b,r_i]^T$$
$\rho_i$是检测概率，后三个参数定义了能见度体积。

### C.问题定义
手头的问题是在给定所有观察结果的情况下，递归计算主车辆相对于地图M的姿态的后验密度。也即，假设主车辆在时间t的姿态由状态$x_t$描述。我们要顺序计算密度
$$p(x_t|f_{1:t},M)$$
此外，在本文中，我们假设车辆状态为
$$x_t = [e_t,n_t,u_t,\nu_t,\beta_t,\alpha_t]$$
其中，$(e_t,n_t,u_t)$是全局坐标系中的位置，$(\nu_t,\beta_t,\alpha_t)$分别是车辆在同一坐标系中的偏航角、俯仰角和侧倾角。

## 3.模型
对于上面定义的问题的过滤解决方案，我们需要定义一个描述状态随时间演变的过程模型和描述状态与观察结果之间的关系的测量模型。
### A.过程模型
我们使用简单的点质量模型对车辆进行建模。过程模型包括两部分，一个部分通过简单的使用速度测量作为输入来模拟运动
$$M(x_t) = \Delta_tM(x_{t-1})\tag{1}$$
$$\Delta = \left[
 \begin{matrix}
   e^{[\Delta t\omega_t+q_t^\omega]_\times} & \Delta tv_t+q_t^v \\
   0 & 1
  \end{matrix}
  \right] \tag{2}$$
其中，