>论文标题：FarSee-Net: Real-Time Semantic Segmentation by Efficient Multi-scale Context Aggregation and Feature Space Super-resolution  
发表时间：2020  
研究组织：商汤科技、东京大学  
本文标签：语义分割、ICRA


# 速读概览：
## 1.针对什么问题？ 
在计算资源有限的机器人应用中实现实时的语义分割。
## 2.采用什么方法？  
级联因子分解多孔空间金字塔池（CF-ASPP）。
## 3.达到什么效果？  
使用单个Nivida Titan X（Maxwell）GPU卡在CityScapes测试集上以84fps的速度实现了68.4%的mIOU。
## 4.存在什么不足？
当输入分辨率降低时，精度也会降低。对于高分辨率输入，运行时间消耗大于基线方法。适合输入尺寸较小的情况。


# 论文精读
## 0.摘要
许多计算资源有限的机器人应用中也想使用实时的语义分割。语义分割的一项挑战是处理对象尺度变化以及利用上下文。如何在有限的计算预算内实现多尺度的上下文聚合十分重要。在本文中，我们首先介绍了一种新颖且高效的模块，名为级联分解空洞空间金字塔池（CF-ASPP）。它是一个卷积神经网络的轻量级级联架构，能有效利用上下文信息。另一方面，为了运行效率，在网络的早期阶段将使用最新的方法快速减小输入或特征图的空间大小。最终的高分辨率结果通常利用非参数上采样操作得到（如双线性插值）。不同的是，我们重新考虑了这条管道，并将其视为一个超分辨率过程。我们在上采样过程中使用优化的超分辨率操作并提高了精度，特别是在实时应用的下采样输入图像场景中。通过融合上述两项改进，我们的方法比其他最先进的方法提供了更好的延迟与精度的平衡。特别是，我们使用单个Nivida Titan X（Maxwell）GPU卡在CityScapes测试集上以84fps的速度实现了68.4%的mIOU。我们所提出的模块可以插入到任何特征提取CNN中，并从CNN结构的发展中受益。


## 1.介绍
* 语义分割是指在给定输入图像的情况下预测所有像素的类别标签的问题。
* 虽然这项任务在深度卷积网络的发展推动下，取得了显著的进展。但是，许多算法依靠需要大量内存和计算成本的复杂模型。这对于需要实时性能且计算资源有限的机器人应用来说是一个挑战。
* 当前基于深度学习的语义分割算法通常包括一个前端网络和一个后端网络。通常使用经过大规模图像分类任务与训练的骨干网络作为特征提取的前端。后端网络通常包含一个用于多尺度上下文聚合的模块（如ASPP、PPM、RefineNet），以及一些连续卷积层生成的最终的密集类别概率图。
* 由于前端网络需要提取高层语义信息，它通常需要具有大量参数的深层网络。当前的实时分割算法为了加快速度，采用两个或多个分支架构作为前端。也有的方法通过设计单薄的网络结构来实现实时性能。然而分割结果的准确性常常会随着实时加速技术而显著降低。
* 由于图像可能包含同一类别不同尺度的对象，如何利用上下文信息对细小物体来说非常重要。在语义分割中，使用深度网络进行多尺度的上下文聚合有着重要作用。当下的上下文聚合模块，如ASPP已经展现了最先进方法的有效性。但这些模块通常工作在网络的深层，其中特征图的通道数非常大。在这种情况下，即使是内核大小为3的卷积层也会消耗大量计算。
* 本文为多尺度上下文重合设计了一个分解的ASPP模块。该模块是轻量级的，可以重复使用来进行更强的上下文融合，而不会明显增加计算量。
* 后端网络用于语义分割的另一个问题在于特征图的空间大小在前端之后大幅减小。此外，很多方法通过使用低分辨率的图像作为输入来提高速度。这对于后端网络非常具有挑战性。
* 目前很多后端网络只是通过双线性插值等无参数操作对特征图进行上采样，得到原始分辨率的结果。但这种方法很难恢复最终分割结果的细节。我们解决该问题的思路是在训练过程中使用较低分辨率的输入图像，但保留高分辨率的真值进行监督。这实际上是从低分辨率输入恢复高分辨率输出的问题，该问题在超分辨率的主题下得到了广泛的研究。
### 本文贡献
1.我们提出了比原始ASPP更快、结果更精准的级联分解ASPP模块。  
2.我们将从低分辨率输入中恢复高分辨率分割结果的问题作为超分辨率处理。 实验结果表明，给定较低分辨率的输入图像，我们的方法的性能下降低于其他方法。 这有助于在保持合理的准确性的同时加速算法。  
3.我们为语义分割提供了一个新的后端网络，与当前最先进的实时语义分割方法相比，本文提出的网络提供了更好的延迟与精度的平衡。此外，我们所提出的网络实现起来非常容易，可以直接与其他现有的特征提取网络结合。这意味着我们的方法可以受益于类似特征提取网络的进步。  


## 2.相关工作
### A.质量驱动的语义分割
* 自FCN引入以来，应用于语义分割的深度学习方面展开了许多研究工作。如何对像素之间的空间关系建模或利用上下文进行推理是当前方法的主要关注点。
* 文献[10]的跳跃连接方法被广泛应用于融合高级语义特征和低级空间线索；ASPP和PPM用于从前端提取特征以融合多尺度上下文；CRF和MRF用于模拟像素或区域之间的空间关系。近来出现了用于语义分割的HRNet，他的整个网络维护者不同分辨率的多个分支。不同分辨率的表示被密集的融合起来。这些方法以大量计算为代价得到了高质量的结果。

### B.实时语义分割
* 这方面的工作旨在保持良好准确性的同时提高模型推理时间。
* ENet是该领域的先驱之一，它设计了一个轻量级的网络架构，并在网络的早期对输入图像进行了大量下采样以减少处理时间。ERFNet采用的是另一种方法，它的网络包含多个分解的卷积块。n×1和1×n卷积的组合用于减少原来的n×n卷积的计算量。
* ICNet、ContextNet、BiSeNet和Fast-SCNN使用深度网络分支输入低分辨率图像学习全局图像上下文，并将其与使用高分辨率输入描述边界信息的较浅的分支得到的特征，或较深的分支早期得到的特征图相结合。
* Li等人设计了一个包含多个子模块的网络。早期模块获取到的特征能重用于后续的模块。
* 不同于上述方法，本文将整个分割网络视作前端与后端的结合，并且我们的工作不需要为前端网络设计特定的主干/特征提取网络。集中于设计高效的后端网络，并可插入到其他的特征提取网络。

### C.通用深度网络加速
* 网络量化应用于卷积参数以获得比浮点计算更好的推理速度。
* 另一方面，网络压缩技术要么使用剪枝操作来减少网络结构，要么使用更大的网络来指导较小网络的训练。
* 许多轻量级骨干网络，若MobileNet和ShuffleNet，也被提出用于使用轻量级构建块进行高效的特征提取。
* 我们提出的网络能够受益于上述方向取得的进展。


## 3.方法
### A.方法概述
* 给定输入RGB图像$I \in \mathbb{R}^{H'\times W'\times 3}$，基于深度学习的语义分割算法通常有连续的卷积层组成，输出为$L \in \mathbb{R}^{H\times W\times N}$。其中N代表分割任务的分类数量，L表示每个像素的类别概率。H和W分别代表图像的高度和宽度。
* 在我们的公式中，我们允许使用低分辨率的输入和高分辨率的输出来加速过程，所以我们有$H'\leq H$和$W'\leq W$。
* 前端网络用于特征提取，我们可以使用现有的深度模型，如VGG、ResNet和MobileNet。
* 对于后端网络，输入的特征图是从前端提取到的，输出是概率图L。这里采用本文提出的CF-ASPP，并与特征空间超分辨率相融合。

### B.CF-ASPP
* 由于对象大小的变化，如何捕捉和融合不同尺度的图像特征对于语义分割很重要。
* 空洞卷积已被广泛用于语义分割。空洞卷积可被视为在每个空间维度上的两个相邻滤波器值之间插入r-1个零，其中r是空洞率。空洞卷积能够在不增加模型参数数量和计算成本的情况下扩大滤波器的视野。
* 另一方面，受到空间金字塔池方法的启发，Chen等人提出用于语义分割的多孔空间金字塔池化。在ASPP中，多个并行的$3\times 3$空洞卷积具有不同的空洞率。这些并行的空洞卷积应用于来自特征提取网络的特征图之上。多种空洞率可以帮助捕获多尺度的上下文信息。
* 但是ASPP应用与从深度网络中得到的特征图。特征图的通道数通常很大。即使内核的大小为$3\times 3$，ASPP依然消耗了大量的计算成本。本文进行以下修改减少这个问题。
* 首先，本文将$3\times 3$的卷积层分为两层。
  * point-wise卷积层（内核大小为$1\times 1$）线性组合输入通道并降低输出通道维数。这层用于进行逐通道的信息交互；
  * depth-wise和与原始空洞卷积具有相同内核大小（$3\times 3$）相同空洞率的空洞卷积。depth-wise卷积是为来降低计算成本。这一层为了让模型能够捕捉到邻近区域的特征。    
        
  令$F_i$和$F_o$分别表示输入和输出的通道数，可以看出，对于原始的$3\times 3$空洞卷积，特征图$M_i \in \mathbb{R}^{h\times w \times F_i}$的计算复杂度为$h \times w \times 3 \times 3 \times F_i \times F_o$，而分解后的计算复杂度为$h \times w \times F_i \times F_o + h \times w \times 3 \times 3 \times F_o$。
* 其次，我们不止应用一次ASPP模块，我们在网络中级联了两个分解的ASPP。这里的动机是我们可以在这种情况下执行广泛的多尺度上下文聚合。另一方面，与原始ASPP相比，分解的ASPP已经减少了很多计算，并且我们在第二个CF-ASPP中使用了更少的通道，级联这个组件不会带来太多的计算成本，但显著提高了准确性。
  
### C.特征空间超分辨率
* 除了核因子分解之外，降低计算成本的一种简单方法是降低输入图像分辨率并将低分辨率结果上采样为高分辨率结果。 然而，从低分辨率恢复高分辨率结果具有挑战性。另一个问题是，经过前端网络的几个阶段后，特征图空间大小也减少了很多。所以我们需要使用低分辨率输入生成高分辨率的分割图。
* 我们把该问题视作一个超分辨率特征空间中的过程。首先，在训练过程中，我们使用下采样RGB图像作为输入，原始的高分辨率类别标签作为真值。其次，对于网络结构设计，我们逐渐上采样后端网络中的特征图。上采样操作由广泛用于图像超分辨率任务的亚像素卷积执行。
* 以下解释如何将亚像素卷积应用到我们的工作中。给定输入特征图$M_i \in \mathbb{R}^{h\times w \times F_i}$和上采样因子t，我们需要输出特征图$M_o \in \mathbb{R}^{tw\times th \times F_i}$。我们将像素级卷积层应用于$M_i$并生成特征图$M_m \in \mathbb{R}^{h\times w \times F_it^2}$。其次，我们应用周期性改组算子将特征图$M_m \in \mathbb{R}^{h\times w \times F_it^2}$中的元素重新排列到特征图$M_o \in \mathbb{R}^{tw\times th \times F_i}$中。与具有相同计算预算的反卷积算子相比，亚像素卷积具有更强的表示能力。


## 4.实验
### A.评估数据集
我们在cityscapes数据集上展开评估，因为它是语义分割研究领域的流行的标准。高分辨率的输入对实时分割算法极具挑战性。根据数据集，官方的准确度标准是平均交并集（IoU）指标。 特别地，我们有 IoU = TP/(TP + FP + FN)，其中 TP、FP 和 FN 分别表示真阳性、假阳性和假阴性的大小。 对于推理速度标准，我们使用直接度量-推理时间。

### B.实施细节
* 本文所提出的算法由Pytorch1.1使用CuDNN v7.0实现，在配备Nvidia Titan X (Maxwell) GPU 的 PC 上运行。
* 在训练阶段，对于前端网络，使用ResNet-18对ImageNet分类任务进行预训练。
* 对于前端网络的高级特征，我们使用全局平均池化层之前最后一个卷积层的特征。 对于低级特征，我们使用来自网络层“conv3 x”的特征。在每个卷积层之后使用批量归一化和 Relu 激活。
* 在训练过程中使用动量 0.9 和批量大小 16 的随机梯度下降 (SGD)。 初始学习率设置为 0.1，每 50 个 epoch 衰减 0.9 倍。 所提出方法的所有实验都训练了 400 个 epoch。 我们还像其他当前方法一样执行广泛的数据增强，包括随机翻转、旋转、颜色通道噪声和调整大小。 与其他方法类似，我们使用交叉熵损失。

### C.网络结构消融研究
为了评估所提出的方法，首先我们使用以下基线方法进行消融研究：
1.前端网络采用 ResNet-18，后端网络采用原始 ASPP 和来自 DeeplabV3+的解码器。
2.前端网络采用 ResNet-18，后端网络包含一个 F-ASPP（没有特征空间分辨率）和来自 DeeplabV3+的解码器。
3.前端网络采用 ResNet-18，后端网络包含 CF-ASPP（没有特征空间分辨率）并没有来自 DeeplabV3+的解码器。
4.提出的完整方法。
通过比较不同的测试用例，我们可以得到以下观察结果。通过比较测试 1、2、3 和 4，我们可以看到，所提出的后端网络的准确性优于来自 DeeplabV3+的原始网络。此外，当输入分辨率降低时，精度也会降低。但是本文提出的方法的精度下降较小。这证明了所提出的特征空间超分辨率方法的有效性。尽管对于高分辨率输入，我们的运行时间消耗大于基线方法1，但我们可以看到，当给定较低分辨率的输入时，情况会发生逆转。这主要是因为所提出方法的额外计算是由层数增加引起的。 给定高分辨率输入，特征图空间尺寸大，层间内存传输消耗很大一部分。 如果输入分辨率较低，则情况相反。 这也表明我们的方法适合输入尺寸较小的情况。  
通过比较Test 5、6、7、8，我们可以看到：
1.通过加入F-ASPP，性能可以得到一点提升，如果我们使用CF-ASPP，则改进会更大。 这证明了 F-ASPP 和级联 F-ASPP 的有效性。
2.F-ASPP 比原来的 ASPP 快（测试 5 和 6）。
3.使用CF-ASPP，无论是运行时间效率还是精度都比原来的（测试5和7）好。
4.通过特征空间超分辨率，我们可以获得更好的结果（测试7和8）。

### D.与其他方法比较
我们还将所提出的方法与其他最先进的实时语义分割算法进行了比较，包括：ENet、ICNet、ContextNet、ESPNetV2、GUN、Fast-SCNN、ERFNet、BiSeNet、LEDNet和 ThunderNet。我们可以看到，与其他方法相比，我们几乎达到了最快的速度。对于准确性，我们的方法也是领先的竞争对手之一。 这表明我们的方法实现了最先进的延迟精度权衡。

### E.定性分析
我们可以看到，所提出的方法可以处理一些小而薄的物体。 从第5排我们可以看到，即使有一些车被遮挡了，它们仍然可以在一定程度上被识别出来。


## 5.结论
本文提出了一种用于实时语义分割的后端网络组件。 一方面，我们提出了一个级联分解的ASPP模块，用于高效的多尺度上下文聚合。 另一方面，为了允许模型使用下采样的低分辨率图像作为输入并生成高分辨率分割输出，我们在特征空间中采用了超分辨率方法。 我们进行了广泛的实验，并证明了这两个方面的有效性。 延迟精度权衡优于许多现有的最先进方法。 未来的研究方向可以是如何将所提出的网络与其他网络加速技术（如网络压缩和量化）相结合。
