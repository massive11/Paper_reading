>论文标题：Boosting Real-Time Driving Scene Parsing with Shared Semantics  
发表时间：2020  
研究组织：上海交通大学、上汽集团  
本文标签：语义分割、自动驾驶、ICRA

# 速读概览：
## 1.针对什么问题？ 

## 2.采用什么方法？  

## 3.达到什么效果？  

## 4.存在什么不足？



# 论文精读
## 0.摘要
* 实时场景解析是具有多个摄像头的自动驾驶车辆的基本功能。本文我们证明了在具有不同视角和重叠视图的摄像头之间共享语义，与传统方法单独处理来自每个相机的帧相比，能够提高解析性能。
* 我们的框架基于用于语义分割的神经网络，但增加了两个用于共享和融合语义的模块。
  * 语义共享模块旨在建立输入图像之间的像素级映射。特征和语义能够被地图共享以减少重复的工作量，从而提高运算效率。
  * 特征融合模块旨在结合不同的语义特征模态，并利用来自两个输入的信息提高准确率。
* 为了评估所提出的框架的效用，我们将网络应用于用于驾驶场景解析的双摄像头视觉系统。实验结果表明，我们的网络在具有可比计算的解析精度上优于基线方法。

## 1.Introduction
* 场景解析是一个密集分类问题，对于在实时应用中实现精确性仍是一项难题，尤其是对具有多个摄像头且计算资源有限的车辆。
* 现在自动驾驶汽车常采用的视觉系统设置是将双目摄像头系统安装在车辆顶部。传统的方法通常单独处理来自每个摄像头的图像，而忽略了双摄像头系统内部的连接。（本文采用的双目摄像头，一个有60度的视野，一个有120度的视野）。由于具有不同视觉的相机具有重叠的感知区域，考虑寻找一种方法来构建像素级的映射以在两个相机之间共享语义和利用不同的补偿加速计算获得精细场景解析结果的视角。
  * 更具体地说，CAM-60 捕获的场景几乎完全包含在来自 CAM-120 的图像中，处理来自 CAM-60 的图像可以受益于从 CAM-120 传播的信息，从而导致更有效的计算。 同时，由于CAM-60具有更大的焦距，对远离车辆的场景有更清晰的感知。 因此 CAM-120 可以融合这些信息以增强其原始分割结果。

* 本文主要贡献：
  * 1.减小视野更窄的相机的计算负载。特征提取过程只需要在不同摄像机之间的重叠区域进行一次。 例如，CAM-60 的繁重和慢速特征提取主干可以替换为轻量级特征提取主干以提取互补特征。 通过语义共享模块从 CAM-120 传播的语义信息为 CAM-60 提供了粗分割，可以通过与其自身特征融合来进一步细化。
  * 提高具有更宽视野的相机的场景解析质量。 例如，来自 CAM-60 的语义特征也使用相同的语义共享模块反向传播到 CAM-120。 通过与 CAM-120 的原始语义适当融合，那些位于重叠区域的语义可以利用 CAM-60 的透视优势进一步增强。


## 2.相关工作
### A.实时场景解析
* 虽然最先进的语义分割网络可以输出高质量的结果，但他们太复杂且计算成本较高，不适合实时应用。
* 一些轻量级语义分割网络被设计为在线工作，同时提供不错的输出。 然而，这些网络并不是为具有多个摄像头的视觉系统而设计的，这使得它们对于自动驾驶应用程序来说仍然过于内存或计算消耗。我们的目标是设计一个优化的架构来减少冗余计算，形成一个更有效的框架。