>书名：深度学习（花书）    
时间：2021年11月1日      
本文标签：深度学习、概率论、信息论

# 3 概率与信息论
## 3.3 概率分布
* 概率分布用来描述随机变量或一簇随机变量在每一个可能取到的状态的可能性大小。

### 3.3.1 离散型变量和概率质量函数
* 离散型变量的概率分布用概率质量函数（PMF）描述。
* 多个变量的概率分布称为联合概率分布

### 3.3.2 连续性变量和概率密度函数
* 连续性变量的概率分布用概率密度函数（PDF）描述。
* 对概率密度函数求积分可以获得点集的真实概率质量

## 3.4 边缘概率
* 从一组变量的联合概率分布中得到自己上的概率分布称为边缘概率分布
* 离散型随机变量的求和法则
  $${\forall x \in X,P(X = x) = \sum _yP(X=x,Y=y)}$$
* 连续性随机变量的积分法
  $${p(x) = \int p(x,y)dy}$$

## 3.5 条件概率
* 条件概率公式
  $${P(Y=y|X=x) = \frac{P(Y=y,X=x)}{P(X=x)}}$$

## 3.6 条件概率的链式法则
* 任何多维随机变量的联合分布都可以分解成只有一个变量的条件概率相乘的形式
  $${P(X^{(1)},...,X^{(n)}) = P(X^{(1)}) \prod_{i=2}^n P(X^{(i)}|X^{(1)}, ..., X^{(i-1)})}$$
  <font color=red>这个规则称为概率的链式法则或者乘法法则</font>

## 3.7 独立性和条件独立性
* 满足下列式子的两个随机变量是相互独立的，记为${x\bot y}$
  $${\forall x \in X,y \in Y,p(X=x,Y=y) = p(X=x)p(Y=y)}$$
* 若关于x和y的条件概率分布对于z的每一个值都可以写成乘积的形式，那么x和y在给定随机变量z时是条件独立的，记为${x\bot y|z}$
  $${\forall x \in X,y \in Y, z \in Z,p(X=x,Y=y|Z=z) = p(X=x|z=z)P(Y=y|Z=z)}$$

## 3.8 期望、方差和协方差
* 离散型随机变量的均值
  $${E_{x \sim p}[f(x)] = \sum_xP(x)f(x)}$$
* 连续型随机变量的均值
  $${E_{x \sim p}[f(x)] = \int p(x)f(x)dx}$$
* 期望是线性的
* 方差衡量的是随机变量的函数值会呈现多大的差异
  $${Var(f(x)) = E[(f(x)-E(f(x)))^2]}$$
* 当方差较小时，$f(x)$的值形成的簇比较接近他们的期望值。方差的平方根被称为标准差。
* 协方差给出了两个变量线性相关性的强度以及这些变量的尺度
  $${Cov(f(x),g(y)) = E[(f(x) - E[f(x)])(g(y) - E[g(y)])]}$$
* 协方差的绝对值如果很大，则变量值变化很大，距离各自的均值较远。
* 如果协方差是正的，则两个变量都倾向于同时取相对较大的值。
* 如果协方差是负的，则一个变量取相对较大的值的同时，另一个变量取相对较小的值。
* （两个变量都取相对较小的值的情况呢？应该也是正的吧）
* 相关系数：将每个变量的贡献归一化，只衡量变量的相关性而不受各个变量尺度大小的影响。
* 如果两个变量相互独立，则协方差为0；若协方差为0，他们之间一定没有线性关系。
* 随机变量$x\in R^n$的协方差矩阵是一个$n \times n$的矩阵，满足
  $${Cov(X)_{i,j} = Cov(X_i,X_j)}$$
* 协方差矩阵的对角元是方差：
  $${Cov(X_i,X_i) = Var(X_i)}$$

## 3.9 常用概率分布
### 3.9.1 Bernoulli分布
* Bernoulli分布是单个二值随机变量的分布
  $${P(X=x) = \phi^x(1-\phi)^{1-x}, \phi \in [0,1]}$$
* 性质如下
  $${E_X[X] = \phi}$$
  $${Var_X(X) = \phi(1-\phi)}$$

### 3.9.2 Multinoulli分布（不太理解）
* Multinoulli分布或者范畴分布是指在具有k个不同状态的单个离散型随机变量上的分布，其中k是一个有限值
* Multinoulli分布由向量${p \in [0,1]^{k-1}}$参数化，其中每一个向量$p_i$表示第i个状态的概率。最后的第k个状态可通过${1 - 1^{\top}p}$给出。
* 常用来表示对象分类的分布，通常不需要计算其均值和方差

### 3.9.3 高斯分布
* 高斯分布也称正态分布
  $${\Nu(x;\mu,\sigma^2) = \sqrt{\frac{1}{2\pi \sigma^2}}e^{-\frac{1}{2\sigma^2}(x-\mu)^2}}$$
* 更高效的参数化方法是使用参数${\beta \in (0, \infty)}$来控制分布的精度
  $${\Nu(x;\mu,\beta^{-1}) = \sqrt{\frac{\beta}{2\pi}}e^{-\frac{\beta}{2}(x-\mu)^2}}$$
* 正态分布是对模型加入的先验知识量最少的分布
* 正态分布推广到${R^n}$空间，称为多维正态分布，其参数是一个正定对称矩阵$\Sigma$
  $${\Nu(x;\mu,\Sigma) = \sqrt{\frac{1}{(2\pi)^n det(\Sigma)}}e^{-\frac{1}{2}(x-\mu)^{\top}\Sigma^{-1}(x-\mu)}}$$
  参数${\Sigma}$给出了分布的协方差矩阵

### 3.9.4 指数分布和Laplace分布
* 指数分布（在x=0处取得边界点的分布）
  $${p(x;\lambda) = \lambda 1_{x \ge 0}e^{-\lambda x}}$$
* Laplace分布允许我们在任意一点${\lambda}$处设置概率质量的峰值：
  $${Laplace(x;\mu,\nu) = \frac{1}{2\nu}e^{-\frac{\vert {x-\mu}\vert}{\nu}}}$$

### 3.9.5 Dirac分布和经验分布
* Dirac delta函数定位概率密度函数（概率分布中的所有质量都集中在一个点上）
  $${p(x) = \delta (x-\mu)}$$
  除了0以外，所有的点的值都为0，但积分为1
* Dirac delta函数属于广义函数，是根据积分性质定义的数学对象
* Dirac delta函数经常作为经验分布的一个组成部分出现
  $${\hat p(x) = \frac{1}{m}\sum_{i=1}^m\delta(x-x^{(i)})}$$