>书名：深度学习（花书）    
时间：2021年11月11日      
本文标签：深度学习、优化

# 8 深度模型中的优化
## 8.1 学习和纯优化有什么不同
* 机器学习中的优化通常是间接作用的。因为机器学习的优化实际是优化定义在测试集上的性能度量P，因此只能通过降低代价函数${J(\theta)}$来间接的优化P。而纯优化最小化目标J本身。
* 代价函数可写成训练集上的平均
  $${J(\theta) = E_{(X,y)\sim \hat p_{data}}L(f(x;\theta),y)}$$
  其中，L是每个样本的损失函数，$f(x;\theta)$是输入x时所预测的输出，$\hat p_{data}$是经验分布。
* 通常我们更希望最小化取自数据生成分布${p_{data}}$的期望，而不仅仅是有限训练及上的对应目标函数
  $${J^*(\theta) = E_{(X,y)\sim  p_{data}}L(f(x;\theta),y)}$$

### 8.1.1 经验风险最小化
* 机器学习算法的目标是降低上式的期望泛化误差。这个数据量被称为风险。
* 将机器学习问题转化回一个优化问题的最简单方法是最小化训练集上的期望损失。这意味着用训练及上的经验分布${\hat p(x,y)}$替代真实分布${p(x,y)}$。现在我们将最小化经验风险，其中m表示训练样本的个数
  $${E_{(X,y)\sim \hat p_{data}}[L(f(x;\theta),y)] = \frac{1}{m}\sum_{i=1}^m L(f(x^{(i)};\theta), y^{(i)})}$$
* 基于最小化这种平均训练误差的训练过程被称为经验风险最小化。
* 但是经验风险最小化很容易导致过拟合，在深度学习中很少使用

### 8.1.2 代理损失函数和提前终止
* 在真正的损失函数不能被高效的优化时，通常会优化代理损失函数，能够在基于提前终止的收敛条件满足时停止。

### 8.1.3 批量算法和小批量算法
* 机器学习中的优化算法在计算参数的每一次更新时通常仅使用整个代价函数中一部分项来估计代价函数的期望值。
* 准确计算训练及上的期望的计算代价非常大，因为需要在整个数据集上的每个样本上评估模型。在实践中，可以从数据集中随机采样少量的样本，然后计算这些样本上的平均值
* 使用整个训练集的优化算法被称为批量或确定性梯度算法，因为他们会在一个大批量中同时处理所有样本。每次只使用单个样本的优化算法有时被称为随机或者在线算法。“在线”通常是指从连续产生样本的数据流中抽取样本的情况，而不是从一个固定大小的训练中遍历多次采样的情况。大多数用于深度学习的算法介于上述二者之间，使用一个以上而又不是全部的训练样本，传统上称为小批量或小批量随机，现在称为随机方法。

## 8.2 神经网络优化中的挑战

### 8.2.1 病态
* 病态问题一般存在于神经网络训练过程中。病态体现在随机梯度下降会卡在某些情况，此时即使很小的更新步长也会增加代价函数。
* 牛顿法在解决带有病态条件的Hessian矩阵的凸优化问题时是一个非常优秀的工具。

### 8.2.2 局部极小值
* 凸优化问题的一个突出特点是其可以简化为寻找一个局部极小点的问题
* 如果一个足够大的训练集可以唯一确定一组模型参数，那么该模型被称为可辨认的

### 8.3 基本算法
#### 8.3.1 随机梯度下降
* SGD算法中的一个关键参数是学习率。在实践中，有必要随着时间的推移逐渐降低学习率

#### 8.3.2 动量
* 虽然随机梯度下降非常受欢迎，但其学习过程有时会很慢，动量方法旨在加速学习，特别是处理高曲率、小但一致的梯度，或是带噪声的梯度。
* 动量算法积累了之前梯度指数级衰减的移动平均，并且继续沿该方向移动。
* 动量的主要目的是解决两个问题
  * Hessian矩阵的病态条件
  * 随机梯度的方差

### 8.4 参数初始化策略
* 深度学习模型的训练算法通常是迭代的，因此要求使用者指定一些开始迭代的初始点。大多数算法都很大程度地受到初始化选择的影响，初始点能够决定算法是否收敛，有些初始点十分不稳定，使得算法遭遇数值困难。当学习收敛时，初始点可以决定学习收敛的多快，以及是否收敛到一个代价高/低的点。初始点也会影响泛化。
* 对于如何初始化网络，正则化和优化有不同的观点。优化观点建议权重应该足够大以成功传播信息，但正则化希望其小一点。
* 在一定程度上，梯度爆炸问题可以通过梯度截断来缓解（执行梯度下降步骤之前设置梯度的阈值）
* 在实践中，需要将权重范围视为超参数

### 8.5 自适应学习率算法
#### 8.5.1 AdaGrad
* 旨在应用于凸问题下快速瘦脸，独立地适应所有模型参数的学习率，缩放每个参数反比于其所有梯度历史平方根总和的平方根。净效果是在参数空间中更为平缓的倾斜方向会取得更大的进步
* 凸优化背景下表现很好。但是经验发现，在训练开始时积累梯度平方会导致有效学习率过早和过量的减小

#### 8.5.2 RMSProp
* RMSProp算法修改AdaGrad以在非凸设定下效果更好，改变梯度积累为指数加权的移动平均
* 相比于AdaGrad，引入了新的超参数，用来控制移动平均的长度范围
* RMSProp是目前深度学习从业者经常采用的优化方法之一

#### 8.5.3 Adam
* Adam通常被认为对超参数的选择相当鲁棒，尽管学习率有时需要从建议的默认修改

#### 8.5.4 选择正确的优化算法
* 如何选择优化算法尚且没有得到共识

### 8.6 二阶近似方法
#### 8.6.1 牛顿法
* 与一阶方法相比，二阶方法使用二阶导数改进了优化。最广泛使用的二阶方法是牛顿法
* 牛顿法是基于二阶泰勒级数展开在某点${\theta_0}$附近来近似${J(\theta)}$的优化方法，忽略了高阶导数
  $${J(\theta) \approx J(\theta_0) + (\theta - \theta_0)^{\top}  \nabla _{\theta}J(\theta_0) + \frac{1}{2} (\theta - \theta_0)^{\top}H(\theta - \theta_0)}$$
  其中，H是J相对于$\theta$的Hessian矩阵在$\theta_0$处的估计。求解该函数的临界点，将得到牛顿参数更新规则
  $${\theta^* = \theta_0 - H^{-1}\nabla_{\theta}J(\theta_0)}$$
* 如果Hessian矩阵的特征值并不都是正的，例如，靠近鞍点处，牛顿法实际上会导致更新朝错误的方向移动。这种情况可以通过正则化Hessian矩阵来避免。常用的正则化策略包括在Hessian矩阵对角线上增加常数$\alpha$
* 牛顿法用于训练大型神经网络受限于计算负担，Hessian矩阵中元素数目是参数数量的平方。只有参数很少的网络才能在实际中用牛顿法训练。

#### 8.6.2 共轭梯度
* 共轭梯度是一种通过迭代下降的共轭方向以有效避免Hessian矩阵求逆计算的方法。

### 8.7 优化策略和元算法
#### 8.7.1 批标准化
* 批标准化实际上并不是一个优化算法，而是一个自适应的重参数化的方法
* 批标准化提出了一种可以重参数化所有深度网络的优雅方法。重参数化显著减少了多层之间协调更新的问题。批标准化可以应用于网络的任何输入层或隐藏层
* 设H是需要标准化的某层的小批量激活函数，排布为设计矩阵，每个样本的激活出现在矩阵的每一行中。为了标准化H，将其替换为
  $${H' = \frac{H - \mu}{\sigma}}$$
  其中，${\mu}$是包含每个单元均值的向量，${\sigma}$是包含每个单元标准差的向量。此处的参数是基于广播向量${\mu}$和向量${\sigma}$应用于矩阵H的每一行。在每一行内，运算是逐元素的。网络的其余操作${H'}$的方式和原网络操作H的方式一样。
  在训练阶段
  $${\mu = \frac{1}{m}\sum_iH_{i,:}}$$
  $${\sigma = \sqrt{\delta + \frac{1}{m}\sum_i (H - \mu)^2_i}}$$
  其中，$\delta$是个很小的值，比如$10^{-8}$，以强制避免遇到$\sqrt{z}$的梯度在$z=0$处为定义的问题。
  最重要的是，我们反向传播这些操作，来计算均值和标准差，并应用它们于标准化H