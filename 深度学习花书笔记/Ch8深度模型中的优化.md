>书名：深度学习（花书）    
时间：2021年11月11日      
本文标签：深度学习、优化

# 8 深度模型中的优化
## 8.1 学习和纯优化有什么不同
* 机器学习中的优化通常是间接作用的。因为机器学习的优化实际是优化定义在测试集上的性能度量P，因此只能通过降低代价函数${J(\theta)}$来间接的优化P。而纯优化最小化目标J本身。
* 代价函数可写成训练集上的平均
  $${J(\theta) = E_{(X,y)\sim \hat p_{data}}L(f(x;\theta),y)}$$
  其中，L是每个样本的损失函数，$f(x;\theta)$是输入x时所预测的输出，$\hat p_{data}$是经验分布。
* 通常我们更希望最小化取自数据生成分布${p_{data}}$的期望，而不仅仅是有限训练及上的对应目标函数
  $${J^*(\theta) = E_{(X,y)\sim  p_{data}}L(f(x;\theta),y)}$$

### 8.1.1 经验风险最小化
* 机器学习算法的目标是降低上式的期望泛化误差。这个数据量被称为风险。
* 将机器学习问题转化回一个优化问题的最简单方法是最小化训练集上的期望损失。这意味着用训练及上的经验分布${\hat p(x,y)}$替代真实分布${p(x,y)}$。现在我们将最小化经验风险，其中m表示训练样本的个数
  $${E_{(X,y)\sim \hat p_{data}}[L(f(x;\theta),y)] = \frac{1}{m}\sum_{i=1}^m L(f(x^{(i)};\theta), y^{(i)})}$$
* 基于最小化这种平均训练误差的训练过程被称为经验风险最小化。
* 但是经验风险最小化很容易导致过拟合，在深度学习中很少使用

### 8.1.2 代理损失函数和提前终止
* 在真正的损失函数不能被高效的优化时，通常会优化代理损失函数，能够在基于提前终止的收敛条件满足时停止。

### 8.1.3 批量算法和小批量算法
* 机器学习中的优化算法在计算参数的每一次更新时通常仅使用整个代价函数中一部分项来估计代价函数的期望值。
* 准确计算训练及上的期望的计算代价非常大，因为需要在整个数据集上的每个样本上评估模型。在实践中，可以从数据集中随机采样少量的样本，然后计算这些样本上的平均值
* 使用整个训练集的优化算法被称为批量或确定性梯度算法，因为他们会在一个大批量中同时处理所有样本。每次只使用单个样本的优化算法有时被称为随机或者在线算法。“在线”通常是指从连续产生样本的数据流中抽取样本的情况，而不是从一个固定大小的训练中遍历多次采样的情况。大多数用于深度学习的算法介于上述二者之间，使用一个以上而又不是全部的训练样本，传统上称为小批量或小批量随机，现在称为随机方法。

## 8.2 神经网络优化中的挑战

### 8.2.1 病态
* 病态问题一般存在于神经网络训练过程中。病态体现在随机梯度下降会卡在某些情况，此时即使很小的更新步长也会增加代价函数。
* 牛顿法在解决带有病态条件的Hessian矩阵的凸优化问题时是一个非常优秀的工具。

### 8.2.2 局部极小值
* 凸优化问题的一个突出特点是其可以简化为寻找一个局部极小点的问题
* 如果一个足够大的训练集可以唯一确定一组模型参数，那么该模型被称为可辨认的