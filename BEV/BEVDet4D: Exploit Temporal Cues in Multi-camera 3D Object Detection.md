>论文标题：BEVDet4D: Exploit Temporal Cues in Multi-camera 3D Object Detection  
发表时间：2022  
研究组织：IEEE    
本文标签：3D目标检测、时序模型


# 速读概览：
## 1.针对什么问题？ 
    
## 2.采用什么方法？  
    
## 3.达到什么效果？  
    
## 4.存在什么不足？



# 论文精读
## 0.Abstract
* 单帧数据的信息有限，限制了当下基于视觉的多相机3D目标检测范式的性能
* 本文提出的BEVDet4D力图将原本只基于空间的3D空间提高到4D空间，通过融合了过去几帧的特征和当前帧的特征的方式更新了原生的BEVDet框架
* we enable BEVDet4D to access the temporal cues by querying and comparing the two candidate features.
* we simplify the task of velocity prediction by removing the factors of ego-motion and time in the learning target.
* As a result, BEVDet4D with robust generalization performance reduces the velocity error by up to -62.9%. This makes the vision-based methods, for the first time, become comparable with those relied on LiDAR or radar in this aspect. On challenge benchmark nuScenes, we report a new record of 54.5% NDS with the high-performance configuration dubbed BEVDet4D-Base, which surpasses the previous leading method BEVDet-Base by +7.3% NDS.

## 1.Introduction

## 3.Methodlogy
### 3.1 Network Structure
* BEVDet is consists of four kinds of modules: an image-view encoder, a view transformer, a BEV encoder, and a task-specific head.
* To exploit the temporal cues, BEVDet4D extends the baseline by retaining the BEV features generated by the view transformer in the previous frame. Then the retained feature is merged with the one in the current frame.

### 3.2. Simplify the Velocity Learning Task
* Instead of directly predicting the velocity of the targets, we tend to predict the translation of the targets between the two adjacent frames.