>论文标题：Fast R-CNN  
发表时间：2015  
研究组织：Microsoft  
本文标签：Fast RCNN、深度学习、ICCV


# 速读概览：
## 1.针对什么问题？ 
    
## 2.采用什么方法？  
    
## 3.达到什么效果？  
    
## 4.存在什么不足？
    


# 论文精读
## 0.摘要
* 本文提出了用于目标检测的Fast R-CNN方法。Fast R-CNN建立在之前的工作上，能够使用深度卷积网络高效的分类目标proposal。与之前的工作相比，Fast R-CNN采用了一些创新方法在提高检测精度的同时提高训练和测试的速度。Fast R-CNN算法训练一个非常深的VGG16网络要比R-CNN快9倍，测试的时间要快213倍，并且在PASCAL VOC2012上取得了更高的mAP。与SPPnet相比，Fast R-CNN训练VGG16的速度快9倍，测试速度快10倍，并且精确率也更高。Fast R-CNN是使用Python和C++（caffe）实现的，开源代码参考https: //github.com/rbgirshick/fast-rcnn.

## 1.Introduction
* 与图像分类相比，目标检测是一个更具挑战性的任务，因为它需要解决更复杂的问题。由于这种复杂性，当下一些采用多阶段通道训练模型的方法慢且不够优雅。
* 目标精确定位的需要导致了复杂度的增长，造成了两个主要挑战。第一，数量庞大的候选Proposal都需要被处理。第二，这些候选框只提供粗略的定位，必须进行优化才能实现精确定位。解决这些问题常常需要在速度、精度或者简单性上进行折中。
* 在本文中，我们简化了基于 ConvNet 的最先进目标检测器的训练过程。 我们提出了一种单阶段训练算法，该算法联同学习目标proposal分类并优化其空间位置。

### 1.1 R-CNN and SPPnet
* R-CNN使用深度ConvNet分类目标proposal实现了优异的精度，但是存在几个著名的缺点
  * 1.训练是多阶段的过程。
        R-CNN先使用log损失函数在目标proposal上微调ConvNet。然后将作为目标检测器使用的SVM作用于特征上，通过微调代替softmax分类器。在第三阶段，学习bounding box回归。
  * 2.训练耗时耗空间。
        对于SVM和bounding box回归器的训练，要从每张图的每个目标proposal上提取特征并存储在磁盘中。在使用如VGG16这样的深度网络时，对于VOC07中的5000张图片的训练需要2.5 GPU-days。这些特征需要数百 GB 的存储空间。
  * 3.目标检测很慢。
        测试时，从每个测试图像中的每个对象提议中提取特征。 使用 VGG16 进行检测需要 47 秒/图像（在 GPU 上）。
* R-CNN要对每个目标proposal实现ConvNet前向传播而不共享计算，因此速度非常慢。
* SPPnets（Spatial pyramid pooling networks）通过共享计算的方式来加速R-CNN。SPPnet对整个输入图像计算一个卷积特征图，然后使用从共享的特征图上提取到的特征分类目标proposal。通过将proposal的特征图部分最大池化为固定大小的输出（例如 6 × 6），为提案提取特征。 多个输出大小被合并，然后在空间金字塔池化 [15] 中进行连接。 SPPnet 在测试时将 R-CNN 加速了 10 到 100 倍。 由于更快的提议特征提取，训练时间也减少了 3 倍。
* SPPnet也有显著的缺点。和R-CNN一样，训练是一个多通道实现的，包括提取特征、使用los损失函数微调网络、训练SVM以及最后的适应性bounding box回归器。特征也是写入到磁盘中。但是和R-CNN不同，微调算法无法更新空间金字塔池化之前的卷积层。 不出所料，这种限制（固定卷积层）限制了非常深的网络的准确性。

### 1.2 Contributions
* 我们提出了一种新的训练算法修复R-CNN和SPPnet的缺点，提升了他们的速度和精度。Fast R-CNN具有以下优点
  * 比R-CNN和SPPnet更高的mAP
  * 训练是单阶段的，使用多任务损失函数
  * 训练可以更新所有的网络参数
  * 不需要为缓存特征消耗磁盘空间


## 2. Fast R-CNN architecture and training
* Fast R-CNN网络将整张图片和一系列目标proposal作为输入。网络首先处理整张图片，通过卷积层和最大池化层产生一个卷积特征图。
* 然后对每个目标proposal，RoI（Region of interest）池化层会从特征图中提取一个固定长度的特征向量。
* 每个特征向量被送入一系列的全连接层，这些层最终分支为两个兄弟输出层；一个生成对K个目标类别和一个包罗万象的背景类别的softmax概率估计，另一层为 K 个对象类中的每一个输出四个实数值。 每组 4 个值为 K 个类别之一编码精炼的边界框位置。

### 2.1 The RoI pooling layer
* RoI池化层使用最大池化将任何有效感兴趣区域内的特征转换为具有固定空间范围H × W（例如 7 × 7）的小特征图，其中 H 和 W 是层超参数，独立于任何特定的RoI。在本文中，RoI 是一个矩形窗口转化成一个卷积特征图。 每个 RoI 由一个四元组 (r, c, h, w) 定义，该元组指定其左上角 (r, c) 及其高度和宽度 (h, w)。
* RoI 最大池化的工作原理是将 h × $\omega$ RoI 窗口划分为一个 H × W 的子窗口网格，大小近似为 h/H × w/W，然后将每个子窗口中的值最大池化到相应的输出网格单元中。 与标准最大池化一样，池化独立应用于每个特征图通道。 RoI 层只是 SPPnets 中使用的空间金字塔池化层的特例，其中只有一个金字塔层。