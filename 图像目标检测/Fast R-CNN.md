>论文标题：Fast R-CNN  
发表时间：2015  
研究组织：Microsoft  
本文标签：Fast RCNN、深度学习、ICCV


# 速读概览：
## 1.针对什么问题？ 
    
## 2.采用什么方法？  
    
## 3.达到什么效果？  
    
## 4.存在什么不足？
    


# 论文精读
## 0.摘要
* 本文提出了用于目标检测的Fast R-CNN方法。Fast R-CNN建立在之前的工作上，能够使用深度卷积网络高效的分类目标proposal。与之前的工作相比，Fast R-CNN采用了一些创新方法在提高检测精度的同时提高训练和测试的速度。Fast R-CNN算法训练一个非常深的VGG16网络要比R-CNN快9倍，测试的时间要快213倍，并且在PASCAL VOC2012上取得了更高的mAP。与SPPnet相比，Fast R-CNN训练VGG16的速度快9倍，测试速度快10倍，并且精确率也更高。Fast R-CNN是使用Python和C++（caffe）实现的，开源代码参考https: //github.com/rbgirshick/fast-rcnn.

## 1.Introduction
* 与图像分类相比，目标检测是一个更具挑战性的任务，因为它需要解决更复杂的问题。由于这种复杂性，当下一些采用多阶段通道训练模型的方法慢且不够优雅。
* 目标精确定位的需要导致了复杂度的增长，造成了两个主要挑战。第一，数量庞大的候选Proposal的位置都需要被处理。第二，这些候选框只提供粗略的定位，必须进行优化才能实现精确定位。解决这些问题常常需要在速度、精度或者简单性上进行折中。
* 在本文中，我们简化了基于 ConvNet 的最先进目标检测器的训练过程。  

### 1.1 R-CNN and SPPnet
* R-CNN使用深度ConvNet分类目标proposal实现了优异的精度，但是存在几个著名的缺点
  * 1.训练是多阶段的过程。
        R-CNN先使用log损失函数在目标proposal上微调ConvNet。然后将作为目标检测器使用的SVM作用于特征上，通过微调代替softmax分类器。在第三阶段，学习bounding box回归。
  * 2.训练耗时耗空间。
        对于SVM和bounding box回归器的训练，要从每张图的每个目标proposal上提取特征并存储在磁盘中。在使用如VGG16这样的深度网络时，对于VOC07中的5000张图片的训练需要2.5 GPU-days。这些特征需要数百 GB 的存储空间。
  * 3.目标检测很慢。
        测试时，从每个测试图像中的每个目标proposal中提取特征。 使用 VGG16 进行检测需要 47 秒/图像（在 GPU 上）。
* R-CNN要对每个目标proposal实现ConvNet前向传播而不共享计算，因此速度非常慢。
* SPPnets（Spatial pyramid pooling networks）通过共享计算的方式来加速R-CNN。SPPnet对整个输入图像计算一个卷积特征图，然后使用从共享的特征图上提取到的特征分类目标proposal。通过将proposal的特征图部分最大池化为固定大小的输出（例如 6 × 6），为proposal提取特征。 多个输出大小被合并，然后在空间金字塔池化中进行连接。 SPPnet 在测试时将 R-CNN 加速了 10 到 100 倍。 由于更快的proposal特征提取，训练时间也减少了 3 倍。
* SPPnet也有显著的缺点。和R-CNN一样，训练是一个多通道实现的，包括提取特征、使用los损失函数微调网络、训练SVM以及最后的适应性bounding box回归器。特征也是写入到磁盘中。但是和R-CNN不同，微调算法无法更新空间金字塔池化之前的卷积层。 不出所料，这种限制（固定卷积层）限制了非常深的网络的准确性。

### 1.2 Contributions
* 我们提出了一种新的训练算法修复R-CNN和SPPnet的缺点，提升了他们的速度和精度。Fast R-CNN具有以下优点
  * 比R-CNN和SPPnet更高的mAP
  * 训练是单阶段的，使用多任务损失函数
  * 训练可以更新所有的网络参数
  * 不需要为缓存特征消耗磁盘空间


## 2. Fast R-CNN architecture and training
* Fast R-CNN网络将整张图片和一系列目标proposal作为输入。
* 网络首先处理整张图片，通过卷积层和最大池化层产生一个卷积特征图。
* 然后对每个目标proposal，RoI（Region of interest）池化层会从特征图中提取一个固定长度的特征向量。
* 每个特征向量被送入一系列的全连接层，这些层最终分支为两个兄弟输出层；一个生成对K个目标类别和一个包罗万象的背景类别的softmax概率估计，另一层为 K 个对象类中的每一个输出四个实数值。 每组 4 个值为 K 个类别之一编码精炼的边界框位置。

### 2.1 The RoI pooling layer
* RoI池化层使用最大池化将任何有效感兴趣区域内的特征转换为具有固定空间范围H × W（例如 7 × 7）的小特征图，其中 H 和 W 是层超参数，独立于任何特定的RoI。在本文中，一个RoI 是一个矩形窗口转化成一个卷积特征图。 每个 RoI 由一个四元组 (r, c, h, w) 定义，该元组指定其左上角 (r, c) 及其高度和宽度 (h, w)。
* RoI 最大池化的工作原理是将 h × $\omega$ RoI 窗口划分为一个 H × W 的子窗口网格，大小近似为 h/H × w/W，然后将每个子窗口中的值最大池化到相应的输出网格单元中。 与标准最大池化一样，池化独立应用于每个特征图通道。 RoI 层只是 SPPnets 中使用的空间金字塔池化层的特例，其中只有一个金字塔层。我们使用的是SPPnet中给出的池化子窗口计算。

### 2.2 Initializing from pre-trained networks
* 当预先训练的网络初始化快速R-CNN网络时，它经历三次转换
  * 首先，最后一个最大池化层被 RoI 池化层替换，该层通过将 H 和 W 设置为与网络的第一个全连接层兼容（例如，对于 VGG16，H = W = 7）进行配置。
  * 其次，网络的最后一个全连接层和 softmax（训练用于1000类别的 ImageNet 分类）被前面描述的两个兄弟层（全连接层和 K+1 类别上的 softmax 和特定类别的边界框回归器）替换。
  * 最后，网络需要两个数据输入，一系列图像和这些图像中的一系列RoI

### 2.3 Fine-tuning for detection
* Fast R-CNN的一个重要能力是使用反向传播训练全部网络权重。首先解释一下为什么SPPnet无法更新空间金字塔池化层下方的权重。
* 最根本的原因在于，当每个训练样本(即ROI)来自不同的图像时，通过SPPlayer的反向传播效率非常低，这正是R-CNN和SPPnet网络的训练方式。效率低的根本在于每个RoI有一个非常大的感受野，常常拓展到整个输入图像。由于前向传播需要处理整个感受域，训练输入非常大。
* 我们提出了一个更加高效的训练方法，在训练过程中利用了特征共享这一特性。在Fast R-CNN训练过程中，随机梯度下降小批次分层采样，首先采样N个图像，然后从每个图像中采样R/N个RoI。重要的是，来自同一图像的ROI在正向和反向传递中共享计算和内存。使 N 的值小会减少小批量计算。 例如，当使用 N = 2 和 R = 128 时，所提出的训练方案比从 128 个不同图像中采样一个 RoI（即 R-CNN 和 SPPnet 策略）大约快 64 倍。
* 对这个策略存在的一个担忧是训练会收敛的很慢，因为来自同一张图的RoI是相关的。这个问题似乎不是一个实际问题，我们在 N = 2 和 R = 128 的情况下使用比 R-CNN 更少的 SGD 迭代取得了良好的结果
* 除了分层采样之外，Fast R-CNN 还使用了一个带有一个微调阶段的简化训练过程，该阶段联合优化了 softmax 分类器和边界框回归器，而不是在三个单独的阶段训练 softmax 分类器、SVM 和回归器。 该过程的组成部分（损失、小批量采样策略、通过 RoI 池化层的反向传播和 SGD 超参数）描述如下。

#### Multi-task loss
* Fast R-CNN网络有两个输出，一个输出精确的概率分布，一个输出bounding box回归偏移${t^k = t_x^k, t_y^k, t_W^k, t_n^k}$。我们使用 [9] 中给出的$t_k$参数化，其中$t_k$指定相对于目标proposal的尺度不变平移和对数空间高度/宽度偏移。