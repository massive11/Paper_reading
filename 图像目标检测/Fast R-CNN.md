>论文标题：Fast R-CNN  
发表时间：2015  
研究组织：Microsoft  
本文标签：Fast RCNN、深度学习、ICCV


# 速读概览：
## 1.针对什么问题？ 
    多阶段通道训练模型的方法慢且不够优雅。
    解决精确定位问题常常需要在速度、精度或者简单性上进行折中。
## 2.采用什么方法？  
    将R-CNN的最后一个池化层使用RoI池化，实现了卷积网络的权重共享。同时将一系列SVM进行分类的方法替换为softmax，采用端到端训练的方式，使用多任务损失函数，使模型直接输出两个结果，一个是目标分类一个是bounding box回归的四元组。
## 3.达到什么效果？  
    比R-CNN和SPPnet更高的mAP和更快的速度
## 4.存在什么不足？
    依然是使用selective search的方式生成proposal，只能在CPU中运行算法，不能够在大量数据上使用


# 论文精读
## 0.摘要
* 本文提出了用于目标检测的Fast R-CNN方法。Fast R-CNN建立在之前的工作上，能够使用深度卷积网络高效的分类目标proposal。与之前的工作相比，Fast R-CNN采用了一些创新方法在提高检测精度的同时提高训练和测试的速度。Fast R-CNN算法训练一个非常深的VGG16网络要比R-CNN快9倍，测试的时间要快213倍，并且在PASCAL VOC2012上取得了更高的mAP。与SPPnet相比，Fast R-CNN训练VGG16的速度快9倍，测试速度快10倍，并且精确率也更高。Fast R-CNN是使用Python和C++（caffe）实现的，开源代码参考https: //github.com/rbgirshick/fast-rcnn.

## 1.Introduction
* 与图像分类相比，目标检测是一个更具挑战性的任务，因为它需要解决更复杂的问题。由于这种复杂性，当下一些采用多阶段通道训练模型的方法慢且不够优雅。
* 目标精确定位的需要导致了复杂度的增长，造成了两个主要挑战。第一，数量庞大的候选Proposal的位置都需要被处理。第二，这些候选框只提供粗略的定位，必须进行优化才能实现精确定位。解决这些问题常常需要在速度、精度或者简单性上进行折中。
* 在本文中，我们简化了基于 ConvNet 的最先进目标检测器的训练过程。  

### 1.1 R-CNN and SPPnet
* R-CNN使用深度ConvNet分类目标proposal实现了优异的精度，但是存在几个著名的缺点
  * 1.训练是多阶段的过程。
        R-CNN先使用log损失函数在目标proposal上微调ConvNet。然后将作为目标检测器使用的SVM作用于特征上，通过微调代替softmax分类器。在第三阶段，学习bounding box回归。
  * 2.训练耗时耗空间。
        对于SVM和bounding box回归器的训练，要从每张图的每个目标proposal上提取特征并存储在磁盘中。在使用如VGG16这样的深度网络时，对于VOC07中的5000张图片的训练需要2.5 GPU-days。这些特征需要数百 GB 的存储空间。
  * 3.目标检测很慢。
        测试时，从每个测试图像中的每个目标proposal中提取特征。 使用 VGG16 进行检测需要 47 秒/图像（在 GPU 上）。
* R-CNN要对每个目标proposal实现ConvNet前向传播而不共享计算，因此速度非常慢。
* SPPnets（Spatial pyramid pooling networks）通过共享计算的方式来加速R-CNN。SPPnet对整个输入图像计算一个卷积特征图，然后使用从共享的特征图上提取到的特征分类目标proposal。通过将proposal的特征图部分最大池化为固定大小的输出（例如 6 × 6），为proposal提取特征。 多个输出大小被合并，然后在空间金字塔池化中进行连接。 SPPnet 在测试时将 R-CNN 加速了 10 到 100 倍。 由于更快的proposal特征提取，训练时间也减少了 3 倍。
* SPPnet也有显著的缺点。和R-CNN一样，训练是一个多通道实现的，包括提取特征、使用los损失函数微调网络、训练SVM以及最后的适应性bounding box回归器。特征也是写入到磁盘中。但是和R-CNN不同，微调算法无法更新空间金字塔池化之前的卷积层。 不出所料，这种限制（固定卷积层）限制了非常深的网络的准确性。

### 1.2 Contributions
* 我们提出了一种新的训练算法修复R-CNN和SPPnet的缺点，提升了他们的速度和精度。Fast R-CNN具有以下优点
  * 比R-CNN和SPPnet更高的mAP
  * 训练是单阶段的，使用多任务损失函数
  * 训练可以更新所有的网络参数
  * 不需要为缓存特征消耗磁盘空间


## 2. Fast R-CNN architecture and training
* Fast R-CNN网络将整张图片和一系列目标proposal作为输入。
* 网络首先处理整张图片，通过卷积层和最大池化层产生一个卷积特征图。
* 然后对每个目标proposal，RoI（Region of interest）池化层会从特征图中提取一个固定长度的特征向量。
* 每个特征向量被送入一系列的全连接层，这些层最终分支为两个兄弟输出层；一个生成对K个目标类别和一个包罗万象的背景类别的softmax概率估计，另一层为 K 个对象类中的每一个输出四个实数值。 每组 4 个值为 K 个类别之一编码精炼的边界框位置。

### 2.1 The RoI pooling layer
* RoI池化层使用最大池化将任何有效感兴趣区域内的特征转换为具有固定空间范围H × W（例如 7 × 7）的小特征图，其中 H 和 W 是层超参数，独立于任何特定的RoI。在本文中，一个RoI 是一个矩形窗口转化成一个卷积特征图。 每个 RoI 由一个四元组 (r, c, h, w) 定义，该元组指定其左上角 (r, c) 及其高度和宽度 (h, w)。
* RoI 最大池化的工作原理是将 h × $\omega$ RoI 窗口划分为一个 H × W 的子窗口网格，大小近似为 h/H × w/W，然后将每个子窗口中的值最大池化到相应的输出网格单元中。 与标准最大池化一样，池化独立应用于每个特征图通道。 RoI 层只是 SPPnets 中使用的空间金字塔池化层的特例，其中只有一个金字塔层。我们使用的是SPPnet中给出的池化子窗口计算。

### 2.2 Initializing from pre-trained networks
* 当预先训练的网络初始化快速R-CNN网络时，它经历三次转换
  * 首先，最后一个最大池化层被 RoI 池化层替换，该层通过将 H 和 W 设置为与网络的第一个全连接层兼容（例如，对于 VGG16，H = W = 7）进行配置。
  * 其次，网络的最后一个全连接层和 softmax（训练用于1000类别的 ImageNet 分类）被前面描述的两个兄弟层（全连接层和 K+1 类别上的 softmax 和特定类别的边界框回归器）替换。
  * 最后，网络需要两个数据输入，一系列图像和这些图像中的一系列RoI

### 2.3 Fine-tuning for detection
* Fast R-CNN的一个重要能力是使用反向传播训练全部网络权重。首先解释一下为什么SPPnet无法更新空间金字塔池化层下方的权重。
* 最根本的原因在于，当每个训练样本(即ROI)来自不同的图像时，通过SPPlayer的反向传播效率非常低，这正是R-CNN和SPPnet网络的训练方式。效率低的根本在于每个RoI有一个非常大的感受野，常常拓展到整个输入图像。由于前向传播需要处理整个感受域，训练输入非常大。
* 我们提出了一个更加高效的训练方法，在训练过程中利用了特征共享这一特性。在Fast R-CNN训练过程中，随机梯度下降小批次分层采样，首先采样N个图像，然后从每个图像中采样R/N个RoI。重要的是，来自同一图像的ROI在正向和反向传递中共享计算和内存。使 N 的值小会减少小批量计算。 例如，当使用 N = 2 和 R = 128 时，所提出的训练方案比从 128 个不同图像中采样一个 RoI（即 R-CNN 和 SPPnet 策略）大约快 64 倍。
* 对这个策略存在的一个担忧是训练会收敛的很慢，因为来自同一张图的RoI是相关的。这个问题似乎不是一个实际问题，我们在 N = 2 和 R = 128 的情况下使用比 R-CNN 更少的 SGD 迭代取得了良好的结果
* 除了分层采样之外，Fast R-CNN 还使用了一个带有一个微调阶段的简化训练过程，该阶段联合优化了 softmax 分类器和边界框回归器，而不是在三个单独的阶段训练 softmax 分类器、SVM 和回归器。 该过程的组成部分（损失、小批量采样策略、通过 RoI 池化层的反向传播和 SGD 超参数）描述如下。

#### Multi-task loss
* Fast R-CNN网络有两个输出，一个输出精确的概率分布，一个输出bounding box回归偏移${t^k = (t_x^k, t_y^k, t_W^k, t_n^k)}$。我们使用 [9] 中给出的$t_k$参数化，其中$t_k$指定相对于目标proposal的尺度不变平移和对数空间高度/宽度偏移。
* 每个训练的RoI被真实类别u和真实的bounding box回归目标v标记。我们使用每个标记的RoI上的多任务损失L联合训练分类和bounding box回归：
  $${L(p,u,t^u,v) = L_{cls}(p,u) + \lambda [u \ge 1]L_{loc}(t^u,v)}$$
  其中，${L_{cls}(p,u) = -log p_u}$是真实类别u的log损失
  第二个任务损失${L_{loc}}$是定义在类别u的真实的bounding box回归目标的元组${v = (v_x,v_y,v_w,v_h)}$和对于类别u的预测元组${t^u = (t_x^u, t_y^u, t_W^u, t_n^u)}$.当 u ≥ 1 时，艾弗森括号指示函数 [u ≥ 1] 评估为 1，否则为 0。 按照惯例，包罗万象的背景类标记为 u = 0。
  对于背景类RoI，没有真实bounding box的概念，${L_{loc}}$也忽略掉。对于bounding box回归，我们使用损失函数
  $${L_{loc}(t^u,v) = \sum_{i\in \{x,y,w,h\}}smooth_{L_1}(t_i^u - v_i)}$$
  其中
  $${smooth_{L_1}(x) = \begin{cases}
0.5x^2, &if\ |x|\ <\ 1\\
|x| - 0.5, &otherwise
\end{cases}}$$
  是一个鲁棒的$L_1$损失对异常值的敏感度低于 R-CNN 和 SPPnet 中使用的$L_2$损失。当回归目标无界时，使用 L2 损失进行训练可能需要仔细调整学习率，以防止梯度爆炸。 上式消除了这种敏感性。
* 损失函数中的超参数$\lambda$控制了两个任务损失之间的平衡。我们将真实回归目标归一化为具有零均值和单位方差。所有实验都使用 λ = 1。

#### Mini-batch sampling
* 在微调过程中，每个SGD小批量由 N = 2 个图像构成，随机均匀选择（按照惯例，我们实际上迭代数据集的排列）。 我们使用大小为 R = 128 的小批量，从每个图像中采样 64 个 RoI。 与 RCNN 一样，我们从目标proposal中获取 25% 的 RoI，这些目标proposal与真实bounding box的IoU至少为 0.5。这些RoI包括由前景目标类别标记的样例，即$u\ge 1$。剩余的RoI是从与真值的IoU值最大且处于区间[0.1, 0.5)的目标proposal中采样的。背景类标记为$u=0$。0.1 的较低阈值似乎充当了困难示例挖掘的启发式方法。 在训练期间，图像以 0.5 的概率水平翻转。 没有使用其他数据增强。

#### 经过RoI池化层的反向传播
* RoI池化层的反向传播函数通过遵循argmax选择计算损失函数相对于每个输入变量$x_i$的偏导
  $${\frac{\partial L}{\partial x_i} = \sum_r \sum_j [i=i^*(r,j) \frac{\partial L}{\partial y_{rj}}]}$$
  换句话说，对于每个小批量 RoI r 和每个池化输出单元 ${y_{rj}}$，如果 i 是通过最大池化为${y_{rj}}$选择的 argmax，则累积偏导${\frac{\partial L}{\partial y_{rj}}}$。在反向传播中，偏导数${\frac{\partial L}{\partial y_{rj}}}$已经由 RoI 池化层顶部的层的反向函数计算出来。

#### SGD超参数
* 用于 softmax 分类和边界框回归的全连接层分别从标准差为 0.01 和 0.001 的零均值高斯分布初始化。 偏差被初始化为 0。所有层都使用 1 的权重和 2 的每层学习率和 0.001 的全局学习率。在 VOC07 或 VOC12 trainval 上训练时，我们运行 SGD 进行 30k 次小批量迭代，然后将学习率降低到 0.0001 并再训练 10k 次迭代。 当我们在更大的数据集上训练时，我们会运行 SGD 进行更多的迭代，如下所述。 使用 0.9 的动量和 0.0005 的参数衰减（权重和偏差）。

### 2.4 Scale invariance
* 我们探究了两种方法实现目标检测的尺度不变性
  * 1.brute force 蛮力学习法
      每个图像在训练和测试期间都以预定义的像素大小进行处理。 网络必须直接从训练数据中学习尺度不变的目标检测。
  * 2.使用图像金字塔
      多尺度方法通过图像金字塔为网络提供近似的尺度不变性。 在测试时，图像金字塔用于近似缩放标准化每个目标proposal。 在多尺度训练期间，我们在每次对图像进行采样时随机采样一个金字塔尺度，遵循SPPnet，作为数据增强的一种形式。 由于 GPU 内存限制，我们仅针对较小的网络进行多尺度训练试验。

## 3. Fast R-CNN detection
### 3.1 Truncated SVD for faster detection
* 对整张图像的分类来说，在全连接层上计算花费的时间比在卷积层上的花费的时间要短。相反，对检测过程而言，要处理的RoI的数量非常大，前向传播几乎一半的时间都花在计算全连接层上。通过使用截断的 SVD 压缩大型全连接层可以轻松实现加速。
* 由u×v权重矩阵W参数化的层使用SVD被近似因式分解为
  $${W = U\sum_t V^T}$$
  在这种分解中，U是由W的前t个左奇异向量组成的$u×t$矩阵，$Σ_t$是包含W的前t个奇异值的$t×t$对角矩阵，V是由W的前t个右奇异向量组成的$v×t$矩阵。截断奇异值分解将参数COUNT从uv减少到t(u+v)，如果t远小于min(u，v)，这一点是非常重要的。为了压缩网络，将对应于W的单连通层替换为两个全连通层，它们之间没有非线性。这些层中的第一层使用权重矩阵$Σ_tV^T$(并且没有偏置)，第二层使用U(具有与W相关联的原始偏置)。这种简单的压缩方法在ROI数很大的情况下有很好的加速比。

## 4. Main results
* 三个主要结论支撑本论文的贡献
  * 在VOC07，2010和2012的最先进的mAP
  * 比起R-CNN和SPPnet更快的训练和测试速度
  * 在VGG16上的微调的卷积层提高了mAP

### 4.1 Experimental setup

### 4.5 Which layers to fine-tune?

## 5. Design evaluation
### 5.1 Does multi-task training help?
* 根据实验结果，提升的效果大概在0.8到1.1的mAP

### 5.2 Scale invariance: to brute force or finesse?
* 由于单比例尺处理提供了速度和精度之间的最佳折衷，特别是对于非常深的模型，因此该子部分之外的所有实验都使用s=600像素的单比例尺训练和测试

### 5.3 Do we need more training data?
* Zhuet al发现SPMmAP训练几百到上千的训练样例后会饱和。我们在增加数据集的样本之后，mAP值都有2%左右的上升。

### 5.4 Do SVMs outperform softmax?
* 对于三个网路来说，softmax都要轻微的优于SVM，约为0.1到0.8的mAP

### 5.5 Are more proposals always better?
* 大致有两种类型的目标检测器：使用稀疏目标proposal集(例如，Selective search)的目标检测器和使用密集集合(例如，DPM)的目标检测器。
* 对稀疏proposal进行分类是一种级联，其中提议机制首先拒绝大量候选，让分类器留下一个小的集合进行评估。 当应用于 DPM 检测时，这种级联提高了检测精度。 我们发现了建议分类器级联也提高了 Fast R-CNN 准确性的证据。 
* 随着proposal数量的提升，mAP的值首先提升，然后略微下降。
* 密集框的统计数据与选择性搜索框的统计数据不同。 从 2k 个选择性搜索框开始，我们在添加 1000 × {2, 4, 6, 8, 10, 32, 45} 密集框的随机样本时测试 mAP。 对于每个实验，我们重新训练和重新测试模型 M。当添加这些密集框时，mAP 比添加更多选择性搜索框时下降得更厉害，最终达到 53.0%。我们还仅使用密集框（45k/图像）训练和测试 Fast R-CNN。 此设置产生 52.9% 的 mAP（蓝色菱形）。 最后，我们检查是否需要带有硬负挖掘的 SVM 来处理密集的框分布。 SVM 的表现更差：49.3%（蓝色圆圈）。

## 6. Conclusion
* 这篇论文提出了Fast R-CNN，一种基于R-CNN和SPPnet的更简洁更快的改进版本。除了报告最先进的检测结果以外，我们给出了我们希望能提供新思路的具体实验。特别值得注意的是，稀疏目标proposal似乎可以提高检测器的质量。 过去这个问题成本太高（及时）而无法探索，但通过 Fast R-CNN 变得可行。 当然，可能存在尚未发现的技术，允许密集框与稀疏proposal一样执行。 如果开发出此类方法，可能有助于进一步加速对象检测。