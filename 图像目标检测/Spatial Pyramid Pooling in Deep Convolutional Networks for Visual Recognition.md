>论文标题：Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition  
发表时间：2015  
研究组织：Microsoft  
本文标签：SPPnet、深度学习、IEEE-TPAMI


# 速读概览：
## 1.针对什么问题？ 
    
## 2.采用什么方法？  
    
## 3.达到什么效果？  
    
## 4.存在什么不足？
    


# 论文精读
## 0.摘要
* 现有的深度卷积网络需要一个固定大小的输入图像（如224×224）。这种需求是人工的，并可能降低任意大小的图像或子图的识别精度。本文中，我们为网络使用了另一种池化策略——空间金字塔池化来消除上述需求。新的网络架构称为SPPnet，能够在任意输入尺寸或规模下生成固定长度的表示。金字塔池化对物体变形也是鲁棒的。有了上述优点，SPPnet应该能够提升所有基于CNN的图像分类网络。在ImageNet2012数据集上，我们证明了SPPnet提高了各种 CNN 架构的准确性，尽管它们的设计不同。 在 Pascal VOC 2007 和 Caltech101 数据集上，SPP-net 使用单个完整图像表示在无微调的情况下实现了最先进的分类结果。  
在目标检测方面，SPPnet也是非常有力的。使用SPPnet只需要从整张图像中计算一次特征图，，然后将任意区域（子图像）中的特征池化以生成用于训练检测器的固定长度表示。 这种方法避免了重复计算卷积特征。在处理测试图像时，我们的方法比 R-CNN 方法快 24-102 倍，同时在 Pascal VOC 2007 上实现了更好或相当的准确度。  
在 ImageNet 大规模视觉识别挑战赛 (ILSVRC) 2014 中，我们的方法在所有 38 个团队中在目标检测中排名第二，在图像分类中排名第三。 这份手稿还介绍了为本次比赛所做的改进。  

## 1.Introduction
* 视觉领域受深度CNN的影响发展的很快。但是在训练和测试CNN的过程中存在技术问题：普遍的CNN结构需要付定的输入图像尺寸，这既限制了输入图像的纵横比，也限制了输入图像的比例。当把任意尺寸的图像送入CNN架构时，输入的图像会以裁剪或扭曲的方式变化到固定尺寸。
* 但是裁剪的区域可能不包含整个对象，扭曲的内容可能会导致不需要的几何失真。识别精度可能会因为内容丢失或失真而受到影响。当目标尺寸变化较大的时候也存在问题。
* CNN为什么需要固定的尺寸：一个CNN主要由两部分组成：卷积层和后面的全连接层。 卷积层以滑动窗口的方式运行，并输出表示激活空间排列的特征图。 事实上，卷积层不需要固定的图像大小，可以生成任意大小的特征图。 另一方面，全连接层需要根据其定义具有固定大小/长度的输入。 因此，固定大小的约束仅来自存在于网络更深阶段的全连接层。
* 在本文中，我们介绍了空间金字塔池化层来消除网络的固定大小约束。具体来说，我们添加了一个SPP层在最后一层卷积层之上。这个SPP层池化特征并生成固定长度的输出，然后被送入全连接层或其他分类器。即我们在网络层次结构的较高阶段（卷积层和全连接层之间）执行一些信息聚合，以避免在开始时需要裁剪或扭曲图像。
* 空间金字塔池化（更为人知的叫法是空间金字塔匹配或者SPM）是词袋（bag-of-words）模型的扩展，它是计算机视觉最成功的算法之一。它将图像从细到粗划分为若干个部分，并将这些部分的局部特征聚合在一起。
* SPP对于深度CNN有以下的重要特性：
  * SPP能够在任意的输入尺寸下生成固定长度的输出，而基于滑动窗口的方法不能
  * SPP使用多级的spatial bins相比滑动窗口只使用单一的窗口大小而言，对目标变形是鲁棒的
  * 由于输入尺度的灵活性，SPP可以汇集在不同尺度下提取的特征。
  上述三点都 提升了深度网络的识别精度
* SPPnet不仅使得测试期间可以使用任意大小的图像，还允许在训练期间使用不同大小的图像。不同大小的图像进行训练增加了尺度不变性，减少过拟合。
* 我们开发了一种多尺寸训练方法。对于能接收可变输入大小的单个网络，我们通过共享所有参数的多个网络来近似它，而这些网络中的每个网络都使用固定的输入大小进行训练。每一轮我们用给定的输入大小训练网络，然后到下一轮变换到另一个输入大小。实验表明，这种多尺度训练和传统的单尺度训练一样能收敛，并且有更高的测试精度。
* 相比于要在每张图像上提取到的2000多个region proposal上一次应用深度CNN提取特征的R-CNN，SPPnet只需要在整张图像上运行一次卷积层，速度约为R-CNN的百倍


## 2.Deep Networks with spatial pyramid pooling
### 2.1 Convolutional layers and feature maps
* 特征图不仅包含响应的强度，还包含它们的空间位置
* 这些编码特征由特征图组成，然后由词袋 (BoW) 或空间金字塔池化。 类似地，可以以类似的方式合并深度卷积特征。

### 2.2 The spatial Pyramid Pooling Layer
* 分类器或全连接层（SVM/softmax）需要固定长度的向量，这些向量可以通过词袋方法将特征池化在一起生成。
* 空间金字塔池化改进了 BoW，因为它可以通过在局部空间块中池化来维护空间信息
* 这些空间块的大小与图像大小成正比，因此无论图像大小如何，空间块的数量都是固定的。这与以前深层网络的滑动窗口池形成对比，其中滑动窗口的数量取决于输入大小
* 在每个空间块中，我们使用最大池化每个每个过滤器的响应。空间金字塔池化的输出是kM维的向量，M是块的数量，k是最后一层卷积层中过滤器的数量。这个固定维度的向量就是全连接层的输入。
* 最粗糙的金字塔层有一个覆盖整个图像的单元格。这实际上是一个全局池化操作。全局池化操作对应于传统的词袋方法。

### 2.3 Training the Network

## 3. SPP-net For Image Classification
### 3.1 Experiments on ImageNet 2021 Classification
#### 3.1.1 Baseline Network Architectures
#### 3.1.2 Multi-level Pooling Improves Accuracy
#### 3.1.3 Multi-size Training Improves Accuracy
#### 3.1.4 Full-image Representations Improve Accuracy
#### 3.1.5 Multi-view Testing on Feature Maps

### 3.2 Experiments on VOC 2007 Classification

### 3.3 Experiments on Caltech101

## 4. SPP-net for Object Detection
* 内容基本都是前面提过的

## 5. Conclusion
* SPP 是一种灵活的解决方案，用于处理不同的比例、大小和纵横比。 这些问题在视觉识别中很重要，但在深度网络的背景下却很少被考虑。 我们提出了一种解决方案来训练具有空间金字塔池化层的深度网络。 由此产生的 SPP-net 在分类/检测任务中表现出出色的准确性，并大大加速了基于 DNN 的检测。 我们的研究还表明，许多经过时间验证的计算机视觉技术/见解仍然可以在基于深度网络的识别中发挥重要作用。