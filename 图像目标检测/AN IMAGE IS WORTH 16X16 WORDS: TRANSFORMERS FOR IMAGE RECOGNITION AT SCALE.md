>论文标题：An Image is Worth 16X16 Words: Transformer for Image Recognition at Scale  
发表时间：2021  
研究组织：Google Research  
本文标签：Transformer、图像目标检测、ICLR


# 速读概览：
## 1.针对什么问题？ 

## 2.采用什么方法？  

## 3.达到什么效果？  

## 4.存在什么不足？



# 论文精读
## 0.摘要
* 虽然 Transformer 架构已成为自然语言处理任务的业界标准，但其在计算机视觉中的应用仍然有限。在视觉上，注意力机制要么与卷积网络结合使用，要么用于替换卷积网络的某些组件，同时保持其整体结构不变。我们展示了这种对于CNN的依赖并不是必须的，将纯transformer直接应用在图像块序列也能在图像分类任务上表现的很好。当对大量数据进行预训练并转移到多个中型或小型图像识别基准时，与最先进的卷积网络相比，Vision Transformer 在大大减少训练的计算资源的同时获得了出色的结果。

## 1.Introduction
* 基于自注意力的架构，特别是Transformer，已经成为NLP领域的首选模型。默认的方法就是在大量词袋上预训练，然后在小型的针对特定任务的数据集上微调。 由于transformer的高效计算和可扩展性，训练参数超过100B的规模空前的模型已经成为可能。随着模型和数据集的增长，仍然没有饱和性能的迹象。
* 在计算机视觉领域，卷积结构依然占据主导地位。受到NLP的成功启发，许多工作开始尝试将自注意力机制与类CNN结构结合，一些甚至完全替代了卷积。后一种模型虽然理论上有效，但由于使用了专门的注意力模式，尚未在现代硬件加速器上有效地扩展。因此，在大规模的图像识别上，经典的类ResNet架构依然是最先进的。
* 受 NLP 中 Transformer 缩放成功的启发，我们尝试将标准 Transformer 直接应用于图像，并尽可能减少修改。