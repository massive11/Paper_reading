>论文标题：Rich feature hierarchies for accurate object detection and semantic segmentation Tech report  
发表时间：2014  
研究组织：UC Berkeley  
本文标签：RCNN、深度学习、CVPR


# 速读概览：
## 1.针对什么问题？ 
    目标检测算法的性能始终没有得到较大的提升，表现最好的方法也是较为复杂的集成系统。
## 2.采用什么方法？  
    本文采用将CNN应用于自下而上的region proposal上提取特征的方式进行目标检测。针对训练数据缺乏的问题，通过在大型数据集上进行预训练的方式可以得到一定程度的改善。
## 3.达到什么效果？  
    与当前表现最好的算法相比，大幅提升了mAP。
## 4.存在什么不足？
    实时性比较一般。


# 论文精读
## 0.摘要
* 在规范的 PASCAL VOC 数据集上测量的目标检测性能在过去几年中趋于稳定。表现最好的方法是复杂的集成系统，通常将多个低级图像特征与高级上下文相结合。本文中，我们提出了一个简单稳定的检测算法，相对于之前在 VOC 2012 上的最佳结果，平均准确率 (mAP) 提高了 30% 以上——实现了 53.3% 的 mAP。我们的方法结合了两个关键观点：1.可以将高容量卷积神经网络 (CNN) 应用于自下而上的region proposal，以定位和分割对象；2.当标记的训练数据稀缺时，先对辅助任务进行有监督的预训练 ，再进行特定任务的微调，会产生显着的性能提升。由于我们将区域建议方法与卷积神经网络相结合，我们将提出的方法称为R-CNN：带有CNN特征的区域。将R-CNN与最近提出的基于类似的CNN架构的滑动窗口检测器OverFeat相比，我们发现 R-CNN 在 200 级 ILSVRC2013 检测数据集上大大优于 OverFeat。

## 1.Introduction
* 特征是非常重要的。过去十年在各种视觉感知任务上取得的成果都是基于SIFT和HOG的使用。但是它们在权威的视觉识别任务上所取得的进展，自2010年到2012年是公认的非常缓慢的，通过构建集成系统和采用成功方法的微小改变只获得了很小的收益。
* 识别发生在下游的几个阶段，这表明可能存在分层的、多阶段的计算特征的过程，这些过程对于视觉识别来说更具信息量。
* 用于模式识别的生物学启发的分层和平移不变模型neocognitron是此类过程的早期尝试，但它缺乏监督学习算法。
* 建立在 Rumelhart 等人的基础上，LeCun 等人表明通过反向传播的随机梯度下降对于训练卷积神经网络 (CNN) 是有效的，CNN 被认为是一类扩展neocognitron的模型。
* CNNs在1990年代被广泛使用，但随即便因为SVM的崛起而淡出研究主流。2012年，Krizhevsky等人在ImageNet大规模视觉识别挑战赛(ILSVRC)上的出色表现重新燃起了世界对CNNs的兴趣（AlexNet）。他们的成功在于在120万的标签图像上使用了一个大型的CNN，并且对LeCUN的CNN进行了一些改造（比如ReLU和Dropout Regularization）。
* 但存在的核心问题是：ImageNet上的CNN分类结果在何种程度上能够应用到PASCAL VOC挑战的物体检测任务上？
* 我们通过连接图像分类和目标检测，回答了这个问题。本论文是第一个说明在PASCAL VOC的物体检测任务上CNN比基于简单类HOG特征的系统有大幅的性能提升。我们主要关注了两个问题：使用深度网络定位物体和在小规模的标注数据集上进行大型网络模型的训练。
* 与图像分类不同的是检测需要定位一个图像内的许多物体。一个方法是将框定位看做是回归问题。但Szegedy等人的工作说明这种策略并不work（在VOC2007上他们的mAP是30.5%，而我们的达到了58.5%）。
* 一种可选择的方法是构造一个滑动窗口检测器。CNN在过去二十多年里一直都是这样使用的，通过一些特定的种类，如人脸和行人。为了保持高空间分辨率，这些CNN方法通常只有两个卷积层和两个池化层。我们也考虑了使用滑动窗口方法，但是由于网络层次更深，输入图片有非常大的感受野（195×195）和 步长（32×32），这使得采用滑动窗口进行精确定位的方法充满挑战。
* 我们是通过操作”recognition using regions”范式，解决了CNN的定位问题，它已经被成功用于目标检测和语义分割中。
* 测试时，我们的方法在每张输入图像上生成了约2000张类别独立的region proposal，使用CNN从每个proposal中提取了固定长度的特征向量，然后使用特定目标的线性SVM对每个region进行分类。我们不考虑region的大小，使用放射图像变形的方法来对每个不同形状的region proposal产生一个固定长度的作为CNN输入的特征向量（也就是把不同大小的proposal放到同一个大小）。
* R-CNN overview：
  * 1.input image
  * 2.Extract region proposals(~2k)
  * 3.compute CNN features from each proposal
  * 4.classify regions
* 检测中遇到的第二个挑战在于缺乏标记数据，当下能使用的数据数量不足以训练一个大型CNN。对于该问题常见的解决思路是使用非监督的预训练，并使用监督进行微调。本文的第二个主要贡献是表明在大型辅助数据集 (ILSVRC) 上进行监督预训练，然后在小数据集 (PASCAL) 上进行特定领域微调，是在数据缺乏的条件下学习大容量 CNN 的有效范例。
* 我们的系统是非常高效的，唯一特定于类的计算是一个相当小的矩阵向量乘积和贪心非极大值抑制。 这种计算特性来自所有类别共享的特征，并且比以前使用的区域特征低两个数量级
* 了解我们方法的故障模式对于改进它也至关重要。 作为该分析的直接结果，我们证明了简单的边界框回归方法显着减少了错误定位，这是主要的错误模式。

## 2. Object detection with R-CNN
* 我们的目标检测系统由三个模块组成。
  * 第一个生成类别独立的region proposals。这些proposals定义了我们的检测器可用的候选检测集。
  * 第二个模块是一个大型CNN，用于从每个region提取长度固定的特征向量
  * 第三个模块是一系列的特定类别的线性SVM。

### 2.1 Module design
#### Region proposals
* 由于R-CNN对特定Region proposal算法是不关心的，所以我们采用了selective search以方便和前面的工作进行可控的比较。

#### Feature extraction
* 我们使用krizhevsky等人描述的CNN的caffe实现的版本从每个region proposal中提取了4096维的特征向量。
* 特征是通过前向传播经过五个卷积层和两个全连接层的一个mean-subtracted的227 × 227 RGB 图像来计算的。
* 为了从region proposal中计算特征，我们必须先把该区域的转化为与CNN兼容的形式（它的结构需要固定输入到227*227的像素尺寸）
* <font color="red">（这一部分不太理解）在任意形状区域的许多可能变换中，我们选择了最简单的。 无论候选区域的大小或纵横比如何，我们都会将其周围紧密边界框中的所有像素扭曲到所需的大小。 在变形之前，我们扩张紧边界框，以便在变形尺寸下，原始框周围正好有 p 个像素的变形图像上下文（我们使用 p = 16）。</font>

### 2.2 Test-time detection
* 我们在每张测试图像上提取大约2000个region proposal。我们将每个proposal进行变形并在CNN上前馈传播以计算特征。然后对于每个类别，我们使用专门针对这个类别进行训练的SVM来对提取到的特征进行评分。对于一张图上所有评分过的region，我们应用一个贪心的极大值抑制方法（对每个类别单独进行），如果该区域具有交叉重叠（IoU）与大于学习阈值的更高评分的选定区域重叠，则拒绝该区域。
#### Run-time analysis
* 两个特性使检测高效。首先，CNN的全部参数在所有类别中共享。其次，与其他通用方法相比，CNN计算得到的特征向量与其他常用的通用方法相比是低维的，如具有视觉词袋编码的空间金字塔。
* 这种共享的结果就是计算region proposal和特征的耗时可以分摊到所有类别头上。唯一的和具体类别有关的计算是特征向量和SVM权重和点积，以及NMS。
* 实践中，所有的点积都可以批量化成一个单独矩阵间运算。特征矩阵的典型大小是2000×4096，SVM权重的矩阵是4096xN，其中N是类别的数量。

### 2.3 Training
#### Supervised pre-training
* 我们在大型辅助训练集ILSVRC2012分类数据集（没有约束框数据）上预训练了CNN。

#### Domain-specific fine-tuning
* 为了让我们的CNN适应新的任务（即检测任务）和新的领域（变形后的推荐窗口）。我们只使用变形后的推荐区域对CNN参数进行SGD训练。

#### Object category classifiers
* 对于检测汽车的二分类器。一个图像区域紧紧包裹着一辆汽车应该就是正例，没有汽车的就是背景区域，也就是负例。较为不明确的是怎样标注哪些只和汽车部分重叠的区域。我们使用IoU重叠阈值来解决这个问题，低于这个阈值的就是负例。这个阈值我们选择了0.3。


## 3. Visualization, ablation, and modes of error
### 3.1 Visualizing learned features

### 3.2 Ablation studies

## 4. The ILSVRC2013 detection datatest

## 5. Semantic segmentation

## 6. conclusion
* 我们取得这个性能主要通过两个方面：第一是应用了自底向上的候选框训练的高容量的卷积神经网络进行定位和分割物体。另外一个是使用在标签数据匮乏的情况下训练大规模神经网络的一个方法。我们展示了在有监督的情况下使用丰富的数据集（图片分类）预训练一个网络作为辅助性的工作是很有效的，然后采用稀少数据（检测）去调优定位任务的网络。我们猜测“有监督的预训练+特定领域的调优”这一范式对于数据稀少的视觉问题是很有效的。