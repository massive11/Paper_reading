>传感器类型：鱼眼相机  
本文标签：自动驾驶、传感器  


鱼眼相机：增强视野，大视野感知
在传统的环视方案中感知本车周边环境是采用大于 180°FOV 的鱼眼相机实现的。随着 L3平台在业界的开发、推广，很多厂商也尝试推广基于环视鱼眼相机的侧视和后视感知方案。一般情况下环视鱼眼相机方案无法达到真正的 L3 +自动驾驶平台的要求。主要原因如下：传统环视相机的安装位置主要是为了提供前、后、左、右 5-10 米的直观视觉，而L3 自动驾驶所关注的左前、右前、左后、右后的位置属于相机图像拼接范围，感知精度受拼接影响；环视相机对远距离和贴近本车的物体的图像造成比较大的变形，在原图中很难准确预测物体的 3D 姿态、大小、和运动轨迹。在矫正的图中因为形变，感知精度降低；环视相机一般为感知近距离路面，安装的 pitch 角度偏低。


# 传统摄像头
## 传统的机器视觉是怎样的？
* 传统摄像头通过间隔曝光，电荷量根据输入光的强度发生变化，以帧率的方式采集平面图像，将捕捉到的光学信息（包括采集点的灰度和颜色）转化成数字信号传输到决策层，实现场景的还原。

## 传统摄像头存在的问题？
* 一是数据不连续，帧的方式只记录了固定时间间隔的画面，还有大量曝光盲区时间点的物体运动信息丢失，同时快速运动场景下图像也不清晰甚至没有记录到；二是输出了大量无效冗余数据，增加芯片负担，造成计算资源浪费。

## 改进思路
* 传统摄像头把 “看到”的所有画面输出到决策层，让芯片过滤筛选有用的信息，这是一种懒办法。所有有人提出了革新，那就是从感知层解决一部分数据，让汽车传感器拥有智慧，主动对信息过滤，并对有用信息加以分析后再输出。

## 改进工具
* 如果使用常用的基于帧（画面）的方法，整个图像是由帧率确定以一定时间间隔输出的。全新的索尼传感器利用变化监测的方法异步检测像素亮度变化并输出带有像素位置（xy坐标）和时间信息的数据。它们采用专有的堆栈式结构，利用Cu-Cu连接实现像素芯片和逻辑芯片之间的导电，逻辑芯片配备了用于检测每个像素亮度变化的信号处理电路。这种设计使得只有检测到物体亮度变化的像素才能输出数据，使传感器能够在低功耗运行状态上以高速度、低延迟、高时间分辨率的方式检测亮度变化。同时，该设计实现了业界最小的※1像素尺寸4.86μm，是非常小型紧凑的高分辨率传感器。