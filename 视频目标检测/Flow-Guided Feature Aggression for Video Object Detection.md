>论文标题：Flow-Guided Feature Aggression for Video Object Detection  
发表时间：2017  
研究组织：USTC、Microsoft    
本文标签：视频目标检测、ICCV


# 速读概览：
## 1.针对什么问题？ 
    针对图像的目标检测方法在处理视频目标检测问题时会出现运动模糊、视频散焦等问题而无法进行精确的检测，而现有的视频目标检测方法只是简单的在box level上进行的，通常是先在单帧中应用目标检测器，然后再专门的后处理步骤中跨时间纬度组装检测到的边界框，处理方法也是现成的运动估计方法和人工设计的边界框关联规则。这种方案实际上并不能提高检测质量，其提升在于启发式后处理，不是原则性的学习，也不存在端到端的训练。
## 2.采用什么方法？  
    视频具有关于同一对象实例的丰富信息，本文通过利用视频中时间信息的连续性，通过将时间上的邻近帧的特征聚合的方式，以原则性的学习进行端到端的训练实现视频目标检测。
## 3.达到什么效果？  
    算法性能与赢得2016ImageNet VID挑战的工程系统相当。
## 4.存在什么不足？
    


# 论文精读
## 0.摘要
* 将最新的目标检测器从图像扩展到视频是具有挑战性的。检测的精度受到视频中目标外观退化的影响，如运动模糊、视频散焦、罕见的姿势等。当前的工作尝试在box level利用时间信息，但这些方法没有经过端到端的训练。我们提出了FGFA方法，这是一种用于视频目标检测的精准的端到端的学习框架。相反，它利用了特征级别的时间连续性。它通过沿运动轨迹聚合邻近的特征提高每一帧的特征，并因此提高视频识别精度。我们的方法显著地提高了ImageNet VID上的单帧基线，特别是更具挑战性的快速移动物体。我们的方法是原则性的，并且与赢得ImageNet VID挑战2016的工程系统相当，没有花里胡哨的东西。本文提出的方法与Deep Feature Flow的组成赢得了ImageNet VID挑战2017

## 1.Introduction
* 在静止的图像上表现良好的框架应用在视频目标检测上存在很多挑战，如运动模糊、视频散焦等现象。这些框架面对快速运动的物体会显著退化
* 视频具有关于同一对象实例的丰富信息
* 现有的一些视频目标检测方法首先在单帧中应用目标检测器，然后在专门的后处理步骤中跨时间维度组装检测到的边界框。通常依赖于现成的运动估计（例如光流）和人工设计的边界框关联规则（例如对象跟踪）。 通常，此类方法操作单帧检测框的质量一般，且不会提高检测质量。性能的提升实际来自启发式后处理，而不是原则性学习。也不存在端到端的训练。以上的方法可以称为box level。
* 由于视频运动，同一目标实例的特征通常不能跨帧实现空间对齐。因此在学习过程中对运动进行建模至关重要。
* 本文提出的方法会针对每一帧提取特征得到每一帧的特征图。为了加强参考帧的特征，光流网络估计了邻近帧到参考帧之间的运动。根据流动运动，邻近帧的特征图被扭曲到参考帧。 扭曲的特征图，以及参考帧的特征图，会通过自适应加权网络进行聚合。 然后将得到的聚合特征图馈送到检测网络以在参考帧上产生检测结果。

## 2.Related work
### 图像目标检测
* 最新的通用目标检测器基本都是基于深度卷积神经网络实现的
* 本文的方法聚焦于基于视频的目标检测，不仅包含了时间信息来提高卷积特征图的质量，还能从静态图像检测器的改善中受益

### 视频目标检测
* 几乎所有现有方法都只在最后一步——边界框后处理这一步中包含时间信息。
* T-CNN 根据预先计算的光流将预测的边界框传播到相邻帧，然后通过应用来自高置信度边界框的跟踪算法生成bounding box的序列。沿着tubelets的边界框经过tubelets分类重新评分。
* Seq-NMS从连续帧中沿着邻近的高置信度边界框构建序列。 序列的框被重新评分为平均置信度，其他接近该序列的框被抑制。
* MCMOT将将后处理过程规划为多目标跟踪问题。使用一系列的手工设计的规则决定边界框是否属于跟踪的目标，并进一步修正跟踪结果。
* 上述方法都是多步实现的思路，每一个阶段的结果都依赖于上一个阶段的结果，因此很难修正之前的阶段产生的误差。

### 基于流的运动估计
* 视频中的时间信息需要原始像素或特征的对应关系，以建立连续帧之间的关系。 光流广泛应用于许多视频分析和处理中。
* 传统方法以变分方法为主，主要解决小位移。 最近的重点是大位移，组合匹配（例如，Deep-Flow、EpicFlow）已被集成到变分方法中。但这些方法都是手工制作的。
* 我们遵循深度特征流的设计，以实现跨帧的特征变形。

### 特征聚合
* 一方面，这些工作中的大多数使用循环神经网络 (RNN) 来聚合连续帧的特征。 另一方面，穷举时空卷积用于直接提取时空特征
* 这些方法中的卷积核大小可能会限制快速移动对象的建模。 为了解决这个问题，应该考虑大的内核大小，但它会大大增加参数数量，导致过拟合、计算开销大和内存消耗的问题。 相比之下，我们的方法依赖于流引导的聚合，并且可以扩展到不同类型的对象运动。

### 视觉跟踪
* 在跟踪新目标时，通过将预训练的 CNN 中的共享层与在线更新的新二元分类层相结合来创建新网络。
* 跟踪和视频目标检测任务有较大的不同，因为它在第一帧中假设一个目标的初始位置并且它不需要预测类别标签

## 3.Flow Guided Feature Aggregation
### 3.1 A baseline and motivation
* 