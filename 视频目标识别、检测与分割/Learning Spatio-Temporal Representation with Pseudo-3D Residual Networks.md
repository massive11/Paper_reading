>论文标题：Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks  
发表时间：2017  
研究组织：MSRA    
本文标签：视频目标识别、ICCV


# 速读概览：
## 1.针对什么问题？ 
    
## 2.采用什么方法？  
    
## 3.达到什么效果？  
    
## 4.存在什么不足？



# 论文精读
## 0.摘要
* CNN已经成为图像识别任务中最强有力的模型之一。然而，使用 CNN 学习时空视频表示并非易事。一些研究表明使用3D卷积是一种捕获视频中空间和时间维度的有益方法。 然而，从头开始开发非常深的 3D CNN 会导致昂贵的计算成本和内存需求。
* 一个有效的问题是为什么不为 3D CNN 回收现成的 2D 网络。 在本文中，我们在残差学习框架中设计了多种瓶颈构建块的变体，通过在空间域（相当于 2D CNN）使用1 × 3 × 3的卷积filter加上3 × 1 × 1的卷积模拟3 × 3 × 3的卷积，以构建在时间维度相邻的特征图上的时间连接。
* 此外，我们提出了一种名为 Pseudo-3D Residual Net (P3D ResNet) 的新架构，它利用块的所有变体，但将每个变体组合在 ResNet 的不同位置，遵循通过深入增强结构多样性可以提高神经网络能力的理念 我们的 P3D ResNet 在 Sports-1M 视频分类数据集上相对于 3D CNN 和基于帧的 2D CNN 分别实现了 5.3% 和 1.8% 的明显改进。 我们进一步检查了我们预先训练的 P3D ResNet 在五个不同的基准和三个不同的任务上生成的视频表示的泛化性能，证明了在几种最先进的技术上的卓越性能。

## 6.Conclusion
* 本文提出的P3D ResNet致力于在深度网络中学习时空视频特征。特别是，我们研究了使用空间维度上的 2D 滤波器和 1D 时间连接来简化 3D 卷积的问题。为了验证我们的主张，我们设计了瓶颈构建块的变体，用于组合 2D 空间和 1D 时间卷积，并将它们集成到不同位置的残差学习框架中，以实现结构多样性。 在 Sports-1M 数据集上学习的 P3D ResNet 架构验证了我们的模型和分析。 在视频动作识别、动作相似性标记和场景识别的背景下对五个数据集进行的实验也证明了我们的 P3D ResNet 生成的时空视频表示的有效性和泛化性。 与其他特征学习技术相比，可以清楚地观察到性能改进。
* 我们今后的工作如下。 首先，注意力机制将被整合到我们的 P3D ResNet 中，以进一步增强表示学习。 其次，将详细研究在训练中增加每个视频剪辑中的帧时 P3D ResNet 的性能如何受到影响。 第三，我们将 P3D ResNet 学习扩展到其他类型的输入，例如光流或音频。