>论文标题：Deep Feature Flow for Video Recognition  
发表时间：2017  
研究组织：USTC、Microsoft      
本文标签：视频目标检测、CVPR


# 速读概览：
## 1.针对什么问题？ 

## 2.采用什么方法？  

## 3.达到什么效果？  

## 4.存在什么不足？



# 论文精读
## 0.摘要
* 深度卷积神经网络在图像识别任务中取得了巨大的成功。然而，将最先进的图像识别网络转移到视频并非易事，因为每帧评估太慢且无法负担。我们提出了深度特征流，一个用于视频识别的快且准确的框架。它只在少量关键帧上运行昂贵的卷积子网，并将它们的深度特征图通过流域传播给其他帧。它实现了显著的速度提升，因为流计算相对来说是比较快的。整个结构能够进行端到端的训练显著提升了识别精度。深度特征流是灵活且通用的。它在目标检测和语义分割的两个视频数据集上得到验证。显着推进了视频识别任务的实践。代码：https:// github.com/msracver/Deep-Feature-Flow.

## 1.Introduction
* 快速准确的视频识别对于高价值场景至关重要，例如自动驾驶和视频监控。然而，在单个视频帧上应用现有的图像识别网络会给大多数应用带来难以承受的计算成本。
* 图像的内容在视频帧上变化的很慢，特别是高级别的语义。这种观察已被用作特征学习中的正则化手段，将视频视为无监督数据源。这样的数据冗余性和连续性也能用来减少计算开销。然而，这方面在文献中使用 CNN 的视频识别很少受到关注。
* 现代CNN的结构大体类似。 中间的卷积特征图和输入图像的空间扩展相同。（通常是较小的分辨率，如16倍或更小）。它们保留了低级图像内容和中高级语义概念之间的空间对应关系。 这种对应提供了通过空间扭曲在附近帧之间廉价传播特征的机会，类似于光流。
* 本文中我们提出了深度特征流，一种用于视频识别的快且准确的方法。它在少量关键帧上应用图像识别网络。通过流域将关键帧的深度特征图传播给其他帧。
* 流估计和特征传播要比卷积特征的计算快得多。计算的瓶颈被避免了，可以实现显著的速度提升。当流域也由网络估计时，整个架构进行端到端的训练，图像识别和流网络都针对识别任务进行了优化。 识别准确率显着提高。
* 总之，深度特征流是一个面向视频识别的快速、准确、通用、端到端的框架。他能将大多数最新的图像识别网络应用于食品领域。就我们所知，这是第一个在深度学习框架中联合训练流和视频识别任务的工作。在最近的大规模视频数据集上进行的大量识别证明了它在视频目标检测和语义分割任务上的有效性。与单帧评估相比，我们的方法实现了前所未有的速度（最多快 10 倍，实时帧速率），但精度损失适中（几个百分点）。

## 2.Related work
* 据我们所知，我们的工作是前所未有的，没有相似的工作可以直接对比。
### Image Recognition
* 基于Region的方法在目标检测领域占据了主导地位，FCN网络在语义分割领域占据了主要地位。然而，将这些图像识别网络直接应用于视频识别的所有帧的计算量无法负担。我们的工作提供了一个高效有用的解决方案。

### Network Acceleration
* 为了降低计算量出现了许多方法。如使用矩阵分解将大型网络层分解为多个小层、量化网络权重等。这些方法都作用于单张图像上。它们都是通用的，可以作为我们的方法的补充。

### Optical Flow
* 这是视频分析领域的基础任务。相关话题已经被研究了几十年，主要被解决小位移的变分方法主导。最近的关注点在于大位移，组合匹配已被整合到变分方法中。 这些方法都是手工制作的。
* 深度学习和语义信息最近也被用于光流中。FlowNet率先使用深度CNN直接估计运动并取得了较好的效果。还有一些其他的工作尝试利用语义分割信息来帮助光流估计，根据区域类别对流提供特定限制。

### Exploiting temporal information in Video Recognition
* T-CNN在视频中结合了来自tubelet的时间和上下文信息。
* dense 3D CRF 提出了语义视频分割中的远程时空正则化
* STFCN考虑了一个用于语义视频分割的稀疏时间的FCN。
* 这些工作对体数据（volume data）进行操作，展示了识别精度的提升，但大大增加了计算成本。 相比之下，我们的方法试图通过利用视频中的时间连贯性来减少计算。网络仍然在单帧上运行并且速度很快。

* **上述反映的内容是，在视频检测领域，时间序列信息主要有两种用法：一是用于借助时间上的临近帧，补充信息，提高识别精度；二是借助时间的连贯性减少计算，提高识别速度。**

### Slow Feature Analysis
* 在视频中，高级别的语义概念通常出现的比低级别的图像要慢。因此，在连续的视频帧上，深度特征变化的也要慢一些。这种现象已经被用于正则化视频中的特征学习。

### Clockwork Convnets
* Clock-work convnets for video semantic segmentation.
* 这篇文章是与本文最相关的工作，它也在某些视频帧上禁用网络中的某些层并重用以前的特征。但比本文要简单、低效的多。
* 在速度的提升方面，Clockwork只保存了部分帧中部分层的计算。我们的方法在大多数帧（例如，10 帧中的 9 帧）中的大多数层（任务网络只有 1 层）上保存了它。 因此，我们的加速比要高得多。
* 在精度方面，Clockwork没有利用帧间的对应关系，只是简单的复制了特征。它仅重新安排现成网络中的推理计算，不执行微调或重新训练。每次的速度提升都会导致显著的精度下降。而我们的工作中精度的下降很小。
* 在通用型方面，Clockwork只能通过FCN应用于语义分割任务。我们的方法则将传统的图像识别网络迁移到视频领域。

## 3.Deep Feature Flow