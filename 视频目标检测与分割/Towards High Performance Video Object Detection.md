>论文标题：Towards High Performance Video Object Detection  
发表时间：2018  
研究组织：MSRA  
本文标签：视频目标检测、CVPR


# 速读概览：
## 1.针对什么问题？ 
DFF利用连续帧之间的数据冗余减少特征计算提高了速度，但损失了精度。FGFA使用时间特征聚合提高特征质量和检测精度，但速度太慢。
## 2.采用什么方法？  

## 3.达到什么效果？  
77.8% mAP at speed of 15.22 fps
## 4.存在什么不足？



# 论文精读
## 0.摘要
* 图像目标检测最近几年已经取得了很大的发展。然而视频目标检测却没有收到很多关注，尽管他更具挑战性并且在实际场景中更加重要。
* 建立在之前的工作之上，本文提出了一种基于多帧端到端特征学习和跨帧运动原理的统一方法。 我们的方法使用三种新技术扩展了先前的工作，并稳步推进性能包络（速度-精度权衡），以实现高性能视频目标检测。

## 1.Introduction
* 静止图像上的目标检测发展的很快，但是直接将这些检测器应用在视频上存在很大的挑战。一是会产生无法负担的计算开销，二是视频中会出现静止图像中少见的外观退化，如运动模糊、视频散焦、rare poses等，这会导致精度下降。
* [DFF](https://github.com/massive11/Paper_reading/blob/master/%E8%A7%86%E9%A2%91%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%88%86%E5%89%B2/Deep%20Feature%20Flow%20for%20Video%20Recognition.md)、[FGFA](https://github.com/massive11/Paper_reading/blob/master/%E8%A7%86%E9%A2%91%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%88%86%E5%89%B2/Flow-Guided%20Feature%20Aggression%20for%20Video%20Object%20Detection.md)表明原则性的多帧端到端学习对于解决上述挑战是有效的。 具体来说，DFF中利用连续帧之间的数据冗余来减少大多数帧上昂贵的特征计算并提高速度。FGFA使用时间特征聚合提高特征质量和检测精度。上述工作是ImageNet Video Object Detection Challenge 2017夺魁的基础。
* 这两项工作的侧重点不同，各有各的弊端。DFF中使用稀疏特征传播保存大部分帧中的昂贵的特征计算量。这些帧的特征是从少量关键帧上廉价的传播得到的。然而，传播的特征只是近似的并且容易出错，从而损害了识别的精度。FGFA使用多帧密集特征聚合提高所有帧上的特征质量和检测精度。但是由于重复的运动估计、特征传播和聚合，它的速度很慢。
* 两部作品在性质上是相辅相成的。 它们也有相同的原理：运动估计模块内置于网络架构中，所有模块的端到端学习都是在多个帧上执行的。
* 基于这些进展和原则，本文提出了一种更快、更准确和更灵活的统一方法。 具体来说，提出了三种新技术。 
  * 首先，稀疏递归特征聚合用于保留聚合的特征质量，但也通过仅对稀疏关键帧进行操作来降低计算成本。 这种技术结合了DFF和FGFA的优点并且比两者都表现得更好。
  * 其次，引入空间自适应部分特征更新以重新计算非关键帧上传播的特征质量较差的特征。 特征质量是通过端到端训练中的新公式学习的。 该技术进一步提高了识别准确度。
  * 最后，时间自适应关键帧调度取代了之前的固定关键帧调度。它根据上面预测的特征质量来预测关键帧的使用情况。它使关键帧的使用更加高效。
* 本文所提出的技术与先前的两项工作是统一的。 综合实验表明，这三种技术稳步推进了性能（速度-精度权衡）包络，朝着高性能视频目标检测方向发展。 我们以每秒 15.22 帧的速度实现了 77.8% 的 mAP 得分。 这是最先进的水平。

## 2.From Image to Video Object Detection
* 当下大部分目标检测器的方法类似，主要由两步实现。
  * 首先通过一个全连接的backbone网络对整张输入图像I提取一系列卷积特征图F。backbone网络通常会在ImageNet分类任务上进行预训练然后再进行微调。本文称其为feature network，${N_{feat}(I) = F}$。它通常比较深并且速度慢，无法负担在全部视频帧上计算的代价。
  * 第二步是通过多分支的子网在稀疏目标proposal或者密集滑动窗口上进行区域分类和bounding box回归生成基于特征图F的检测结果y。本文称其为detection network， ${N_{det}}(F) = y}$。它是随机初始化的，并与${N_{feat}}$联合训练，通常是浅层且快速的。

### 2.1 Revisiting Two Baseline Methods on Video
#### Sparse Feature Propagation(DFF)
* 它率先引入了视频目标检测的关键帧的概念。其动机是邻近帧的相似的外观通常有相似的特征。因此没有必要在所有帧上计算特征。
* 在推理过程中，昂贵的特征网络${N_{feat}}$只应用于稀疏的关键帧上（每10th）。任何非关键帧 i 上的特征图都是通过每像素特征值扭曲和双线性插值从其前面的关键帧 k 传播的。帧间逐像素运动记录在二维运动域${M_{i\rightarrow k}}$中。从关键帧k到帧i的传播可以表示为：
$${F_{k\rightarrow i} = W(F_k, M_{i \rightarrow k}) \tag{1}}$$
其中，${W}$表示特征变形函数。然后检测网络${N_{det}}$作用在${F_{k\rightarrow i}$上，用真实特征的近似${F_{i}}$取代了根据${N_{feat}}$计算${F_{i}}$。
* 运动域是通过光流网络估计的，${N_{flow}(I_k, I_i) = M_{i \rightarrow k}}$，它将两帧${I_k, I_i}$作为输入。包括${N_{flow}}$在内的所有模块的端到端训练，大大提高了检测精度，弥补了特征逼近带来的不准确性。与单帧检测器相比，由于${N_{flow}}$和公式(1)的计算比${N_{feat}}}$中的特征提取要便宜得多，DFF方法要快得多，精度下降很小（几个mAP点）。

#### Dense Feature Aggregation（FGFA）
* 它率先引入了视频目标检测中的时序特征融合的概念。其动机是特定帧中深层的特征会被退化的特征（如运动模糊、遮挡）损坏，但是可以通过邻近帧的融合来提高。
* 在推理过程中，特征网络${N_{feat}}$在每一帧上密集的评估。对每一帧i，时间窗口${[i − r, i + r]}$（r = 2 ∼ 12 帧）内所有帧的特征图首先以与 dff 相同的方式变形到帧 i 上，形成一系列特征图${F_{k \rightarrow i}|k \in [i-r, i+r]}$。与稀疏特征传播不同，传播发生在每一帧而不仅仅是关键帧。换言之，每一帧都被视为关键帧。
* 得到帧i的聚合特征图${\overline F_i}$作为所有这些特征图的加权平均值
$${\overline{ F_i(p) = \sum_{k \in [i-r, i+r]}}}$$