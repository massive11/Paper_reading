>论文标题：Towards High Performance Video Object Detection  
发表时间：2018  
研究组织：MSRA  
本文标签：视频目标检测、CVPR


# 速读概览：
## 1.针对什么问题？ 
DFF利用连续帧之间的数据冗余减少特征计算提高了速度，但损失了精度。FGFA使用时间特征聚合提高特征质量和检测精度，但速度太慢。
## 2.采用什么方法？  

## 3.达到什么效果？  
77.8% mAP at speed of 15.22 fps
## 4.存在什么不足？



# 论文精读
## 0.摘要
* 图像目标检测最近几年已经取得了很大的发展。然而视频目标检测却没有收到很多关注，尽管他更具挑战性并且在实际场景中更加重要。
* 建立在之前的工作之上，本文提出了一种基于多帧端到端特征学习和跨帧运动原理的统一方法。 我们的方法使用三种新技术扩展了先前的工作，并稳步推进性能包络（速度-精度权衡），以实现高性能视频目标检测。

## 1.Introduction
* 静止图像上的目标检测发展的很快，但是直接将这些检测器应用在视频上存在很大的挑战。一是会产生无法负担的计算开销，二是视频中会出现静止图像中少见的外观退化，如运动模糊、视频散焦、rare poses等，这会导致精度下降。
* [DFF](https://github.com/massive11/Paper_reading/blob/master/%E8%A7%86%E9%A2%91%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%88%86%E5%89%B2/Deep%20Feature%20Flow%20for%20Video%20Recognition.md)、[FGFA](https://github.com/massive11/Paper_reading/blob/master/%E8%A7%86%E9%A2%91%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%88%86%E5%89%B2/Flow-Guided%20Feature%20Aggression%20for%20Video%20Object%20Detection.md)表明原则性的多帧端到端学习对于解决上述挑战是有效的。 具体来说，DFF中利用连续帧之间的数据冗余来减少大多数帧上昂贵的特征计算并提高速度。FGFA使用时间特征聚合提高特征质量和检测精度。上述工作是ImageNet Video Object Detection Challenge 2017夺魁的基础。
* 这两项工作的侧重点不同，各有各的弊端。DFF中使用稀疏特征传播保存大部分帧中的昂贵的特征计算量。这些帧的特征是从少量关键帧上廉价的传播得到的。然而，传播的特征只是近似的并且容易出错，从而损害了识别的精度。FGFA使用多帧密集特征聚合提高所有帧上的特征质量和检测精度。但是由于重复的运动估计、特征传播和聚合，它的速度很慢。
* 两部作品在性质上是相辅相成的。 它们也有相同的原理：运动估计模块内置于网络架构中，所有模块的端到端学习都是在多个帧上执行的。
* 基于这些进展和原则，本文提出了一种更快、更准确和更灵活的统一方法。 具体来说，提出了三种新技术。 
  * 首先，稀疏递归特征聚合用于保留聚合的特征质量，但也通过仅对稀疏关键帧进行操作来降低计算成本。 这种技术结合了DFF和FGFA的优点并且比两者都表现得更好。
  * 其次，引入空间自适应部分特征更新以重新计算非关键帧上传播的特征质量较差的特征。 特征质量是通过端到端训练中的新公式学习的。 该技术进一步提高了识别准确度。
  * 最后，时间自适应关键帧调度取代了之前的固定关键帧调度。它根据上面预测的特征质量来预测关键帧的使用情况。它使关键帧的使用更加高效。
* 本文所提出的技术与先前的两项工作是统一的。 综合实验表明，这三种技术稳步推进了性能（速度-精度权衡）包络，朝着高性能视频目标检测方向发展。 我们以每秒 15.22 帧的速度实现了 77.8% 的 mAP 得分。 这是最先进的水平。

## 2.From Image to Video Object Detection
* 当下大部分目标检测器的方法类似，主要由两步实现。
  * 首先通过一个全连接的backbone网络对整张输入图像I提取一系列卷积特征图F。backbone网络通常会在ImageNet分类任务上进行预训练然后再进行微调。本文称其为feature network，${N_{feat}(I) = F}$。它通常比较深并且速度慢，无法负担在全部视频帧上计算的代价。
  * 第二步是通过多分支的子网在稀疏目标proposal或者密集滑动窗口上进行区域分类和bounding box回归生成基于特征图F的检测结果y。本文称其为detection network， ${N_{det}}(F) = y}$。它是随机初始化的，并与${N_{feat}}$联合训练，通常是浅层且快速的。

### 2.1 Revisiting Two Baseline Methods on Video
#### Sparse Feature Propagation(DFF)
* 